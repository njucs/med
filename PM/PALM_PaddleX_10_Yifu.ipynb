{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njucs/med/blob/master/PM/PALM_PaddleX_10_Yifu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTlR2fqwJoFL"
      },
      "source": [
        "**本方案使用TNT模型进行训练与预测，在有限训练次数下，取得了较稳定的成绩：0.99515**\n",
        "\n",
        "**采取的训练图像预处理方案：**\n",
        "\n",
        "- 随机垂直翻转\n",
        "- 随机角度翻转--0~20度\n",
        "- 缩放大小--（520，520）\n",
        "- 归一化--mean:[0.2, 0.3, 0.5], std:[0., 0., 0.]\n",
        "\n",
        "**采取的验证与预测图像预处理方案：**\n",
        "\n",
        "- 缩放大小--（520，520）\n",
        "- 归一化--mean:[0.2, 0.3, 0.5], std:[0., 0., 0.]\n",
        "- 数据集划分比例：0.8\n",
        "\n",
        "**TNT模型比较：**\n",
        "\n",
        "- 微调参数： tnt_s_patch16_224 得分 > tnt_b_patch16_224 得分\n",
        "\n",
        "**针对Yifu数据集：**\n",
        "\n",
        "数据预处理：要处理成正方形，切除外围的黑色区域\n",
        "\n",
        "数据增强：（N/H增加1+1+1倍，P增加1+12+12倍）\n",
        "- 水平翻转\n",
        "- 随机向外缩放20%以内\n",
        "- 随机旋转+/-10度以内\n",
        "- 高斯噪声（opt）\n",
        "（填充都是黑色）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_UpfeIEdr3g"
      },
      "source": [
        "## PaddleX配置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXF3enlRdtmw"
      },
      "source": [
        "### paddlex安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obdbrdr1lePI"
      },
      "outputs": [],
      "source": [
        "# install PaddlePaddle-GPU\n",
        "!python -m pip install paddlepaddle-gpu==2.2.2 -i https://mirror.baidu.com/pypi/simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "327IadTzQ6N9"
      },
      "outputs": [],
      "source": [
        "!pip install paddlex==1.3.11 -i https://mirror.baidu.com/pypi/simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2raUegcHg0K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import paddle\n",
        "from paddle import nn\n",
        "from paddle import optimizer\n",
        "from paddle import regularizer\n",
        "from paddle import metric\n",
        "from paddle.nn import loss\n",
        "from paddle.nn import Layer\n",
        "\n",
        "from paddle.io import Dataset, DataLoader\n",
        "from paddle.vision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcXcIYl4eInK"
      },
      "source": [
        "## 准备数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFjwp8QieKg5"
      },
      "source": [
        "### 准备数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uNgUT5Pw5VV",
        "outputId": "bc045292-1430-4265-b89b-d49fde3572cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Ophthalmology/PathologicMyopia\n"
          ]
        }
      ],
      "source": [
        "# 授权 Colab 访问 Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/MyDrive/'Colab Notebooks'/Ophthalmology/PathologicMyopia/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skjCHL0gyD4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43e0992-0cf3-43ce-c0eb-fbb281c56ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "800\n",
            "400\n"
          ]
        }
      ],
      "source": [
        "!ls dataset-yifu | wc -w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o488t5FqHml8",
        "outputId": "4f41273e-ff05-4414-83f3-fe680287f21e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     imgName  Label\n",
              "0  V0001.jpg      0\n",
              "1  V0002.jpg      1\n",
              "2  V0003.jpg      1\n",
              "3  V0004.jpg      0\n",
              "4  V0005.jpg      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d18e809-b216-4151-a69b-045a433d0747\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imgName</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>V0001.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>V0002.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>V0003.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V0004.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>V0005.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d18e809-b216-4151-a69b-045a433d0747')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d18e809-b216-4151-a69b-045a433d0747 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d18e809-b216-4151-a69b-045a433d0747');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "########## 重写，自动随机划分Train/Test集\n",
        "\n",
        "Image_path = 'dataset-yifu'\n",
        "Train_data = pd.read_excel('dataset/Train/Classification.xlsx')\n",
        "Train_data.head()\n",
        "\n",
        "for i in range(len(Train_data)):\n",
        "    Train_data.iloc[i, 0] = os.path.join(Image_path, Train_data.iloc[i, 0])\n",
        "Train_data = Train_data.sample(frac=1.0).reset_index(drop=True)\n",
        "Train_data.head()\n",
        "\n",
        "Test_data = []\n",
        "Test_path = 'dataset/Test'\n",
        "for _, _, files in os.walk(Test_path):\n",
        "    for i in files:\n",
        "        Test_data.append([i, 0])\n",
        "Test_data = np.asarray(Test_data)\n",
        "Test_data = pd.DataFrame(Test_data)\n",
        "Test_data = Test_data.sort_values(by=0, ascending=True).reset_index(drop=True)\n",
        "for i in range(len(Test_data)):\n",
        "    Test_data.iloc[i, 0] = os.path.join(Test_path, Test_data.iloc[i, 0])\n",
        "Test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7HlY3rgHvuj"
      },
      "outputs": [],
      "source": [
        "class Train_Dataset(Dataset):\n",
        "    '''加载训练集\n",
        "        把数据加载函数拼进来\n",
        "    '''\n",
        "    def __init__(self, df, trans=None):\n",
        "        super(Train_Dataset, self).__init__()\n",
        "\n",
        "        self.df = df\n",
        "        \n",
        "        if trans is None:\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.RandomVerticalFlip(),\n",
        "                transforms.RandomRotation(20),\n",
        "                transforms.Resize(size=(520, 520)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.2, 0.3, 0.5])\n",
        "            ])\n",
        "        else:\n",
        "            self.trans = trans\n",
        "\n",
        "        self.lens = len(df)\n",
        "\n",
        "    def __getitem__(self, indexs):\n",
        "        im_data, im_label = self._load_img_and_label(self.df, indexs)\n",
        "        im_data = self.trans(im_data)\n",
        "        return im_data, paddle.to_tensor(im_label)\n",
        "\n",
        "    def _load_img_and_label(self, df, index):\n",
        "        '''加载DF中的路径为图片和标签\n",
        "            df: 输入DF\n",
        "            index: 第几条数据\n",
        "            mode: 加载训练集数据模式还是测试集模式--区别在于是否转换数据域\n",
        "        '''\n",
        "        assert index < self.lens, \\\n",
        "            'please check the index, which has more than the dataset length!'\n",
        "\n",
        "        im_data = cv.imread(df.iloc[index, 0], cv.COLOR_BGR2RGB)  # 转为RGB数据\n",
        "        im_label = int(df.iloc[index, 1])  # 标签\n",
        "        return np.asarray(im_data).astype('float32'), im_label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.lens\n",
        "\n",
        "class Test_Dataset(Dataset):\n",
        "    '''加载测试集\n",
        "        把数据加载函数拼进来\n",
        "    '''\n",
        "    def __init__(self, df, trans=None):\n",
        "        super(Test_Dataset, self).__init__()\n",
        "\n",
        "        self.df = df\n",
        "        \n",
        "        if trans is None:\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.Resize(size=(520, 520)),  # 保证迁移前后输入特征大小一致\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.2, 0.3, 0.5])\n",
        "            ])\n",
        "        else:\n",
        "            self.trans = trans\n",
        "\n",
        "        self.lens = len(df)\n",
        "\n",
        "    def __getitem__(self, indexs):\n",
        "        im_data, im_label = self._load_img_and_label(self.df, indexs)\n",
        "        im_data = self.trans(im_data)\n",
        "        return im_data, paddle.to_tensor(im_label)\n",
        "\n",
        "    def _load_img_and_label(self, df, index):\n",
        "        '''加载DF中的路径为图片和标签\n",
        "            df: 输入DF\n",
        "            index: 第几条数据\n",
        "            mode: 加载训练集数据模式还是测试集模式--区别在于是否转换数据域\n",
        "        '''\n",
        "        assert index < self.lens, \\\n",
        "            'please check the index, which has more than the dataset length!'\n",
        "\n",
        "        im_data = cv.imread(df.iloc[index, 0], cv.COLOR_BGR2RGB)  # 转为RGB数据\n",
        "        im_label = int(df.iloc[index, 1])  # 标签\n",
        "        return np.asarray(im_data).astype('float32'), im_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scPbUAv_elRe"
      },
      "source": [
        "## 训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33FldCMwIF3t"
      },
      "outputs": [],
      "source": [
        "# 训练参数-=dict\n",
        "Train_Paramdict = {\n",
        "    'data_length':len(Train_data),  # 数据长度\n",
        "    'train_frac':0.8,              # 训练集比例\n",
        "    'num_class':2,                  # 类别\n",
        "    'epoches':20,                   # 训练轮次\n",
        "    'batchsize':8,                 # 批量大小\n",
        "    'lr':0.0001,                      # 学习率\n",
        "    'l2':0.0005                    # L2正则化参数\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wrzhd0t6IIUu"
      },
      "outputs": [],
      "source": [
        "# 数据集划分\n",
        "Fit_data  = Train_data.iloc[:int(Train_Paramdict['data_length']*Train_Paramdict['train_frac'])]\n",
        "Eval_data = Train_data.iloc[int(Train_Paramdict['data_length']*Train_Paramdict['train_frac']):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8cWKOtzIKip"
      },
      "outputs": [],
      "source": [
        "# 数据加载\n",
        "Fit_dataset = Train_Dataset(Fit_data)\n",
        "Eval_dataset = Test_Dataset(Eval_data)\n",
        "All_dataset = Train_Dataset(Train_data)\n",
        "\n",
        "Fit_dataloader = DataLoader(Fit_dataset, batch_size=Train_Paramdict['batchsize'], shuffle=True)\n",
        "Eval_dataloader = DataLoader(Eval_dataset, batch_size=Train_Paramdict['batchsize'])\n",
        "All_dataloader = DataLoader(All_dataset, batch_size=Train_Paramdict['batchsize'], shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oucAFJgNrpF"
      },
      "outputs": [],
      "source": [
        "import paddle\n",
        "from paddle import nn\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def _cfg(url='', **kwargs):\n",
        "    return {\n",
        "        'url': url,\n",
        "        'num_classes': 2, 'input_size': (3, 600, 600), 'pool_size': None,\n",
        "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
        "        'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5),\n",
        "        'first_conv': 'pixel_embed.proj', 'classifier': 'head',\n",
        "        **kwargs\n",
        "    }\n",
        "\n",
        "\n",
        "default_cfgs = {\n",
        "    'tnt_s_patch16_224': _cfg(\n",
        "        url='',\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "    'tnt_b_patch16_224': _cfg(\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "class Identity(nn.Layer):\n",
        "    r\"\"\"A placeholder identity operator that is argument-insensitive.\n",
        "    Args:\n",
        "        args: any argument (unused)\n",
        "        kwargs: any keyword argument (unused)\n",
        "    Examples::\n",
        "        >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)\n",
        "        >>> input = torch.randn(128, 20)\n",
        "        >>> output = m(input)\n",
        "        >>> print(output.size())\n",
        "        torch.Size([128, 20])\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "\n",
        "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
        "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
        "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
        "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
        "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
        "    'survival rate' as the argument.\n",
        "    \"\"\"\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = keep_prob + paddle.rand(shape=shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor()  # binarize\n",
        "    output = x.divide(keep_prob) * random_tensor\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "class DropPath(nn.Layer):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)\n",
        "\n",
        "\n",
        "class Attention(nn.Layer):\n",
        "    '''\n",
        "        注意力部分\n",
        "    '''\n",
        "\n",
        "    def __init__(self, dim, hidden_dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = hidden_dim // num_heads\n",
        "        self.head_dim = head_dim\n",
        "        self.scale = head_dim ** -0.5\n",
        "\n",
        "        self.qk = nn.Linear(dim, hidden_dim * 2, bias_attr=qkv_bias)\n",
        "        self.v = nn.Linear(dim, dim, bias_attr=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)  # no inplace\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        B, N, C = x.shape\n",
        "        qk = self.qk(x).reshape((B, N, 2, self.num_heads, self.head_dim)).transpose((2, 0, 3, 1, 4))\n",
        "        q, k = qk[0], qk[1]\n",
        "        v = self.v(x).reshape((B, N, self.num_heads, -1)).transpose((0, 2, 1, 3))\n",
        "\n",
        "        attn = paddle.matmul(q, k.transpose((0, 1, 3, 2))) * self.scale\n",
        "        attn = paddle.nn.functional.softmax(attn, axis=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = paddle.matmul(attn, v).transpose((0, 2, 1, 3)).reshape((B, N, -1))\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Mlp(nn.Layer):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super(Mlp, self).__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Layer):\n",
        "    \"\"\" TNT Block\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, in_dim, num_pixel, num_heads=12, in_num_head=4, mlp_ratio=4.,\n",
        "            qkv_bias=False, drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
        "        super(Block, self).__init__()\n",
        "        # Inner transformer\n",
        "        self.norm_in = norm_layer(in_dim)\n",
        "        self.attn_in = Attention(\n",
        "            in_dim, in_dim, num_heads=in_num_head, qkv_bias=qkv_bias,\n",
        "            attn_drop=attn_drop, proj_drop=drop)\n",
        "        \n",
        "        self.norm_mlp_in = norm_layer(in_dim)\n",
        "        self.mlp_in = Mlp(in_features=in_dim, hidden_features=int(in_dim * 4),\n",
        "            out_features=in_dim, act_layer=act_layer, drop=drop)\n",
        "        \n",
        "        self.norm1_proj = norm_layer(in_dim)\n",
        "        self.proj = nn.Linear(in_dim * num_pixel, dim, bias_attr=True)\n",
        "        # Outer transformer\n",
        "        self.norm_out = norm_layer(dim)\n",
        "        self.attn_out = Attention(\n",
        "            dim, dim, num_heads=num_heads, qkv_bias=qkv_bias,\n",
        "            attn_drop=attn_drop, proj_drop=drop)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else Identity()\n",
        "        \n",
        "        self.norm_mlp = norm_layer(dim)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=int(dim * mlp_ratio),\n",
        "            out_features=dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward(self, pixel_embed, patch_embed):\n",
        "        # inner\n",
        "        pixel_embed = pixel_embed + self.drop_path(self.attn_in(self.norm_in(pixel_embed)))\n",
        "        pixel_embed = pixel_embed + self.drop_path(self.mlp_in(self.norm_mlp_in(pixel_embed)))\n",
        "        # outer\n",
        "        B, N, C = patch_embed.shape\n",
        "        patch_embed[:, 1:] = patch_embed[:, 1:] + self.proj(self.norm1_proj(pixel_embed).reshape((B, N - 1, -1)))\n",
        "        patch_embed = patch_embed + self.drop_path(self.attn_out(self.norm_out(patch_embed)))\n",
        "        patch_embed = patch_embed + self.drop_path(self.mlp(self.norm_mlp(patch_embed)))\n",
        "        return pixel_embed, patch_embed\n",
        "\n",
        "\n",
        "class PixelEmbed(nn.Layer):\n",
        "    \"\"\" Image to Pixel Embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, in_dim=48, stride=4):\n",
        "        super(PixelEmbed, self).__init__()\n",
        "        num_patches = (img_size // patch_size) ** 2\n",
        "        self.img_size = img_size\n",
        "        self.num_patches = num_patches\n",
        "        self.in_dim = in_dim\n",
        "        new_patch_size = math.ceil(patch_size / stride)\n",
        "        self.new_patch_size = new_patch_size\n",
        "\n",
        "        self.proj = nn.Conv2D(in_chans, self.in_dim, kernel_size=7, padding=3, stride=stride)\n",
        "\n",
        "    def forward(self, x, pixel_pos):\n",
        "        B, C, H, W = x.shape\n",
        "        assert H == self.img_size and W == self.img_size, \\\n",
        "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size}*{self.img_size}).\"\n",
        "        x = self.proj(x)\n",
        "        x = nn.functional.unfold(x=x, kernel_sizes=self.new_patch_size, strides=self.new_patch_size)\n",
        "\n",
        "        x = x.transpose((0, 2, 1)).reshape((B * self.num_patches, self.in_dim, self.new_patch_size, self.new_patch_size))\n",
        "        x = x + pixel_pos\n",
        "\n",
        "        x = x.reshape((B * self.num_patches, self.in_dim, -1)).transpose((0, 2, 1))\n",
        "        return x\n",
        "\n",
        "\n",
        "class TNT(nn.Layer):\n",
        "    \"\"\" Transformer in Transformer - https://arxiv.org/abs/2103.00112\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, in_dim=48, depth=12,\n",
        "                 num_heads=12, in_num_head=4, mlp_ratio=4., qkv_bias=False, drop_rate=0., attn_drop_rate=0.,\n",
        "                 drop_path_rate=0., norm_layer=nn.LayerNorm, first_stride=4):\n",
        "        super(TNT, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
        "\n",
        "        self.pixel_embed = PixelEmbed(\n",
        "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, in_dim=in_dim, stride=first_stride)\n",
        "        num_patches = self.pixel_embed.num_patches\n",
        "        self.num_patches = num_patches\n",
        "        new_patch_size = self.pixel_embed.new_patch_size\n",
        "        num_pixel = new_patch_size ** 2\n",
        "        \n",
        "        self.norm1_proj = norm_layer(num_pixel * in_dim)\n",
        "        self.proj = nn.Linear(num_pixel * in_dim, embed_dim)\n",
        "        self.norm2_proj = norm_layer(embed_dim)\n",
        "            \n",
        "        # 创建参数\n",
        "        self.cls_token = paddle.create_parameter((1, 1, embed_dim), 'float32', attr=nn.initializer.Assign(paddle.zeros((1, 1, embed_dim))))\n",
        "        self.patch_pos = paddle.create_parameter((1, num_patches + 1, embed_dim), 'float32', attr=nn.initializer.Assign(paddle.zeros((1, num_patches + 1, embed_dim))))\n",
        "        self.pixel_pos = paddle.create_parameter((1, in_dim, new_patch_size, new_patch_size), 'float32', attr=nn.initializer.Assign(paddle.zeros((1, in_dim, new_patch_size, new_patch_size))))\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "\n",
        "        dpr = [x for x in paddle.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
        "        blocks = []\n",
        "        for i in range(depth):\n",
        "            blocks.append(Block(\n",
        "                dim=embed_dim, in_dim=in_dim, num_pixel=num_pixel, num_heads=num_heads, in_num_head=in_num_head,\n",
        "                mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, drop=drop_rate, attn_drop=attn_drop_rate,\n",
        "                drop_path=dpr[i], norm_layer=norm_layer))\n",
        "        self.blocks = nn.LayerList(blocks)\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "        self.head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "        with paddle.no_grad():\n",
        "            self.cls_token = paddle.create_parameter(self.cls_token.shape, 'float32', attr=nn.initializer.Assign(paddle.normal(self.cls_token, std=.02)))\n",
        "            self.patch_pos = paddle.create_parameter(self.patch_pos.shape, 'float32', attr=nn.initializer.Assign(paddle.normal(self.patch_pos, std=.02)))\n",
        "            self.pixel_pos = paddle.create_parameter(self.pixel_pos.shape, 'float32', attr=nn.initializer.Assign(paddle.normal(self.pixel_pos, std=.02)))\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            with paddle.no_grad():\n",
        "                m.weight = paddle.create_parameter(m.weight.shape, 'float32', attr=nn.initializer.Assign(paddle.normal(m.weight, std=.02)))\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                m.bias = paddle.create_parameter(m.bias.shape, 'float32', attr=nn.initializer.Constant(value=0.))\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            m.bias = paddle.create_parameter(m.bias.shape, 'float32', attr=nn.initializer.Constant(value=0.))\n",
        "            m.weight = paddle.create_parameter(m.weight.shape, 'float32', attr=nn.initializer.Constant(value=1.))\n",
        "\n",
        "    def no_weight_decay(self):\n",
        "        return {'patch_pos', 'pixel_pos', 'cls_token'}\n",
        "\n",
        "    def get_classifier(self):\n",
        "        return self.head\n",
        "\n",
        "    def reset_classifier(self, num_classes, global_pool=''):\n",
        "        self.num_classes = num_classes\n",
        "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        B = x.shape[0]\n",
        "        pixel_embed = self.pixel_embed(x, self.pixel_pos)\n",
        "        \n",
        "        patch_embed = self.norm2_proj(self.proj(self.norm1_proj(pixel_embed.reshape((B, self.num_patches, -1)))))\n",
        "        patch_embed = paddle.concat((self.cls_token.expand([B, self.cls_token.shape[1],self.cls_token.shape[2]]), patch_embed), axis=1)  # expand\n",
        "        patch_embed = patch_embed + self.patch_pos\n",
        "        patch_embed = self.pos_drop(patch_embed)\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            pixel_embed, patch_embed = blk(pixel_embed, patch_embed)\n",
        "\n",
        "        patch_embed = self.norm(patch_embed)\n",
        "        return patch_embed[:, 0]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def tnt_s_patch16_224(pretrained=False, **kwargs):\n",
        "    model = TNT(patch_size=16, embed_dim=384, in_dim=24, depth=12, num_heads=6, in_num_head=4,\n",
        "        qkv_bias=False, **kwargs)\n",
        "    model.default_cfg = default_cfgs['tnt_s_patch16_224']\n",
        "    if pretrained:\n",
        "        load_pretrained(\n",
        "            model, num_classes=model.num_classes, in_chans=kwargs.get('in_chans', 3))\n",
        "    return model\n",
        "\n",
        "\n",
        "def tnt_b_patch16_224(pretrained=False, **kwargs):\n",
        "    model = TNT(patch_size=16, embed_dim=640, in_dim=40, depth=12, num_heads=10, in_num_head=4,\n",
        "        qkv_bias=False, **kwargs)\n",
        "    model.default_cfg = default_cfgs['tnt_b_patch16_224']\n",
        "    if pretrained:\n",
        "        load_pretrained(\n",
        "            model, num_classes=model.num_classes, in_chans=kwargs.get('in_chans', 3))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kggqrRytemhy"
      },
      "outputs": [],
      "source": [
        "# 创建模型\n",
        "#import tnt_s_patch16_224, tnt_b_patch16_224\n",
        "model = tnt_s_patch16_224(img_size=520, num_classes=2)\n",
        "model = paddle.Model(model)\n",
        "\n",
        "lr = optimizer.lr.LinearWarmup(\n",
        "    learning_rate=Train_Paramdict['lr'],\n",
        "    warmup_steps = 2000,\n",
        "    start_lr = 0, \n",
        "    end_lr = Train_Paramdict['lr']\n",
        ")\n",
        "\n",
        "O = optimizer.Adam(lr, parameters=model.parameters(), weight_decay=regularizer.L2Decay(Train_Paramdict['l2']))\n",
        "L = loss.CrossEntropyLoss()\n",
        "M = metric.Accuracy()\n",
        "\n",
        "model.prepare(O, L, M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxf3l3cdIQ2O"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    Fit_dataloader,\n",
        "    Eval_dataloader,\n",
        "    epochs=Train_Paramdict['epoches']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V19HnpEheuLT"
      },
      "source": [
        "## 预测"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ue9m2Rve5AA"
      },
      "outputs": [],
      "source": [
        "# 数据加载\n",
        "Test_dataset = Test_Dataset(Test_data)\n",
        "Test_dataloader = DataLoader(Test_dataset, batch_size=Train_Paramdict['batchsize'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzPEkjK6IXyx"
      },
      "outputs": [],
      "source": [
        "results = model.predict(Test_dataloader)\n",
        "results = np.asarray(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agUbO4zBIaNM"
      },
      "outputs": [],
      "source": [
        "import paddle.nn.functional as F\n",
        "\n",
        "submit_result = []\n",
        "for i in results[0]:\n",
        "    i = paddle.to_tensor(i)\n",
        "    i = F.softmax(i)\n",
        "    result = i[:, 1]\n",
        "    submit_result += result.numpy().tolist()\n",
        "len(submit_result)\n",
        "\n",
        "submit_result = np.asarray(submit_result)\n",
        "\n",
        "Test_data.iloc[:, 1] = submit_result\n",
        "Test_data.head()\n",
        "\n",
        "Submit_data = Test_data.copy()\n",
        "Submit_data.head()\n",
        "\n",
        "Submit_data.columns = ['FileName', 'PM Risk']\n",
        "Submit_data.head()\n",
        "\n",
        "for i in range(len(Submit_data)):\n",
        "    Submit_data.iloc[i, 0] = Submit_data.iloc[i, 0][-9:]\n",
        "Submit_data.head()\n",
        "\n",
        "# Submit_data.to_csv('PALM_PaddleX_10/Classification_Results.csv', index=False, float_format=\"%.1f\")\n",
        "Submit_data.to_csv('Yifu/Classification_Results.csv', index=False, float_format=\"%.1f\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PALM_PaddleX_10_Yifu.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGcqByTM+lRJtlTCqQ0AJ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}