{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJvCWbWblO4Nn7HD2lVo3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njucs/med/blob/master/PM/PM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kao1HUozaR5B",
        "outputId": "5836c55a-e9bf-479c-968b-2640e659e7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 授权 Colab 访问 Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/'Colab Notebooks'/Ophthalmology/PathologicMyopia/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9imbL6Caa8w",
        "outputId": "2272dabe-b55a-4d22-8823-e8fb1ebc7cc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Ophthalmology/PathologicMyopia\n",
            "/content/drive/MyDrive/Colab Notebooks/Ophthalmology/PathologicMyopia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset/PALM-Training400 -l"
      ],
      "metadata": {
        "id": "9bn59Wfwjm8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset/PALM-Training400/PALM-Training400 -l"
      ],
      "metadata": {
        "id": "cv5UrcfyUJ4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset/PALM-Validation400 -l"
      ],
      "metadata": {
        "id": "Zs2tEnhoULIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## anshu123priya/Classification-of-Pathological-Myopia\n",
        "\n",
        "Classify the fundus photos from PM patients into three labels- Pathological Myopia, High Myopia and Normal labels.\n",
        "\n",
        "This project we've taken as BTP under Dr. Sandeep Yadav which was a very new grand challenge of 2019. In which we've provided total 400images as our training datasets, 213 for pathological myopia, 161 for normal label and only 26images for high myopia. So, our main task was to deal with very less and unbalanced datasets. We built a modal using ResNet and VGGNet 16 in which we got the maximum accuracy with ResNet model after using data augmentation as we've very unbalanced datasets. To resolve the problem of unbalanced dataset we also try of class weight but we didn't achieve that much accuracy. After that we used categorical cross entropy as our loss function which is nothing but the combination of softmax activation function and cross entropy loss function.\n",
        "\n",
        "Achieved 94.39% accuracy and 0.9075 F1 score on publicly available datasets MICCAI 2019 PALM with base model ResNet."
      ],
      "metadata": {
        "id": "qkU63KPb-uj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet_fine_tune_008"
      ],
      "metadata": {
        "id": "ogjJFcT5-Wey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Reshape\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "#from keras.applications.alexnet import AlexNet,preprocess_input\n",
        "#from keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from keras.models import model_from_json,model_from_config,load_model\n",
        "from keras.optimizers import SGD,RMSprop,adam,Adam\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from keras import models\n",
        "from keras import layers as lay\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from numpy import *\n",
        "import os\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "# sets the image shape specification to be (num_images,num_rows,num_columns,num_channels) \n",
        "#as if the backend is Theano num_channels come as the second argument\n",
        "\n",
        "def get_model():\n",
        "# function to make the model and compile it\n",
        "\n",
        "\tbase_model = ResNet50()\n",
        "\t#base_model = VGG16(weights='imagenet', include_top=True)\n",
        "\t# imports the base Resnet50 model and stores it in base_model along with the preloaded ImageNet weights \n",
        "\n",
        "\tbase_model.summary()\n",
        "\t#prints the summary of the resnet model\n",
        "\t\n",
        "\tfl1 = base_model.get_layer('predictions').output\n",
        "\t#get the output of the layer of resnet with the name flatten_1\n",
        "\tfc1=Dense(1000,activation='relu')(fl1)\n",
        "\t#add a fully connected layer with 1000 neurons to the fl1 layer and apply relu activation on it\n",
        "\n",
        "\tdrop1=Dropout(0.3)(fc1)\n",
        "\t#add a dropout of 0.3 i.e kill 30% of the neurons at random to introduce generecity and avoid overfitting\n",
        "\n",
        "\tfc2=Dense(400,activation='relu')(drop1)\n",
        "\tdrop2=Dropout(0.3)(fc2)\n",
        "\t# add the fully connected layer with 500 neurons and apply a dropout of 0.3 same as the previous layer\n",
        "\tfc3=Dense(150,activation='relu')(drop2)\n",
        "\tdrop3=Dropout(0.3)(fc3)\n",
        "\tfc4=Dense(40,activation='relu')(drop3)\n",
        "\tdrop4=Dropout(0.3)(fc4)\n",
        "\t#fc5=Dense(50,activation='relu')(drop4)\n",
        "\t#drop5=Dropout(0.3)(fc5)\n",
        "\t#fc6=Dense(20,activation='relu')(drop5)\n",
        "\t#drop6=Dropout(0.3)(fc6)\n",
        "\tpredictions = Dense(3,activation='softmax')(drop4)\n",
        "\t# finally drop the model to 2 class prediction since we have to classify between two classes \n",
        "\t#and apply softmax activation since it gives us the class probabilities between 0 and 1\n",
        "\n",
        "\t# till now layers have been stacked onto one another\n",
        "\n",
        "\n",
        "\tmodel = Model(base_model.input, predictions)\n",
        "\t# specifies a model whose input layer is the input layer of the resnet model and output layer is \n",
        "\t# the predictions layer which gives the class probabilities of the two classes\n",
        "\n",
        "\tfor layer in base_model.layers:\n",
        "\t\tlayer.trainable=False\n",
        "\t# since resnet is already trained on the imagenet dataset it has already learned the basic features\n",
        "\t# such as lines , curves etc and thus we freeze the resnet model to avoid computation and save time\n",
        "\t# Hence these two lines set all the layers in the resnet model to not be trainable so that only the \n",
        "\t# fully connected layers that we have added are trainable\n",
        "\n",
        "\tadam=Adam(lr=0.001)\n",
        "\t# define a customised adam optimizer with a learning rate of 0.001. \n",
        "\t# You can also set other parameters such as momentum and decay\n",
        "\n",
        "\tmodel.compile(optimizer=adam, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\t# compile the model means to create a computation graph so that it knows that it has to use the\n",
        "\t# adam optimizer and compute the categorical cross-entropy loss during back propogation\n",
        "\t# also we define which all metrics we have to take track of. Loss is by default and we have\n",
        "\t# accuracy as well. But till now the model is just a graph and no data has been fed into it.\n",
        "\n",
        "\tmodel.summary()\n",
        "\t# prints the summary of the whole model we have just created\n",
        "\n",
        "\treturn model\n",
        "\t# return the made and compiled model\n",
        "\n",
        "def get_input():\n",
        "\tX=[]\n",
        "\tlabel=[]\n",
        "\tpath1=\"no_aug\"\n",
        "\tpath2=\"pathological_aug\"\n",
        "\tpath3=\"high_aug\"\n",
        "\tlist1=os.listdir(path1)\n",
        "\tlist2=os.listdir(path2)\n",
        "\tlist3=os.listdir(path3)\n",
        "\tfor elem in list1:\n",
        "\t\timg=image.load_img(path1+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(0)\n",
        "\tfor elem in list2:\n",
        "\t\timg=image.load_img(path2+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(1)\n",
        "\tfor elem in list3:\n",
        "\t\timg=image.load_img(path3+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(2)\n",
        "\tX=preprocess_input(np.array(X))\n",
        "\tlabel=np.array(label)\n",
        "\tprint (\"input taken\")\n",
        "\treturn X,label\n",
        "\n",
        "def fit_model(model,X,label):\n",
        "# function to train our model on the data given by X and its groundtruth given by label\n",
        "\n",
        "\tX_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.2, random_state=2)\n",
        "\t# split the data as 20% testing and 80% training with a random state of 2. Random state means that\n",
        "\t# everytime the data is randomly shuffled and then split but using the same random state means that\n",
        "\t# the data is shuffled similarly every time but if you change it to any other number it will shuffle\n",
        "\t# differently\n",
        "\n",
        "\tmodel_json = model.to_json()\n",
        "\t# converts the model architecture into a json file\n",
        "\n",
        "\twith open(\"model.json\", \"w\") as json_file:\n",
        "\t\tjson_file.write(model_json)\n",
        "\t\tprint(\"json saved\")\n",
        "\t# writes the model architecture into the json file named as model.json\n",
        "\n",
        "   \t#checkpoint=ModelCheckpoint(\"Model.h5\",monitor='val_acc',mode='max',save_best_only=True,save_weights_only=True)\n",
        "   \t# creates a checkpoint such that after every epoch it automatically saves the model weights \n",
        "   \t# monitor defines what we have to keep track of which in this case is validation accuracy.For\n",
        "   \t# training accuracy you can write acc and for loss write loss or val_loss\n",
        "   \t# Model.h5 defines the path where we want to save the weights\n",
        "   \t# mode defines when we have to save the weights when the thing being monitored is maximum or minimum\n",
        "   \t# save_best_only set to True means that only the best model is saved and save_weights_only means that\n",
        "   \t# only the model weights are stored since we have already stored the json file\n",
        "\n",
        "   \t# *********** it is always recommended to save the json and weights independently instead of the whole model at once **********\n",
        "\n",
        "   \t#callbacks_list=[checkpoint]\n",
        "   \t# creates a list of the checkpoint\n",
        "\t\n",
        "\n",
        "\t\n",
        "\t\n",
        "\n",
        "\tmodel.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=15, batch_size=32)\n",
        "\t#callbacks=callbacks_list\n",
        "\t# fits the model i.e provides the data to the built model to train it\n",
        "\t# X_train and y_train are the training data and the corresponding groundtruth\n",
        "\t# X_test and y_test are the validation data on which the trained model will be tested after every epoch\n",
        "\t# 15 epochs means that 15 iterations of training will be done\n",
        "\t# batch_size=32 refers \n",
        "\tscores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\tprint (\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "X,label=get_input()\n",
        "X,label=shuffle(X,label,random_state=2)\n",
        "model=get_model()\n",
        "fit_model(model,X,label)"
      ],
      "metadata": {
        "id": "mzVcZCu8-YTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet_DataGenerator"
      ],
      "metadata": {
        "id": "3bB7okk9-hld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Reshape\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "#from keras.applications.alexnet import AlexNet,preprocess_input\n",
        "#from keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from keras.models import model_from_json,model_from_config,load_model\n",
        "from keras.optimizers import SGD,RMSprop,adam,Adam\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from keras import layers as lay\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from numpy import *\n",
        "import os\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "# sets the image shape specification to be (num_images,num_rows,num_columns,num_channels) \n",
        "#as if the backend is Theano num_channels come as the second argument\n",
        "\n",
        "def get_model():\n",
        "# function to make the model and compile it\n",
        "\n",
        "\t#base_model = VGG16()\n",
        "\tbase_model = ResNet50()\n",
        "\n",
        "\n",
        "\t# imports the base Resnet50 model and stores it in base_model along with the preloaded ImageNet weights \n",
        "\n",
        "\tbase_model.summary()\n",
        "\t#prints the summary of the resnet model\n",
        "\t\n",
        "\tfl1 = base_model.get_layer('fc1000').output\n",
        "\t#get the output of the layer of resnet with the name flatten_1\n",
        "\n",
        "\tfc1=Dense(1000,activation='relu')(fl1)\n",
        "\t#add a fully connected layer with 1000 neurons to the fl1 layer and apply relu activation on it\n",
        "\n",
        "\tdrop1=Dropout(0.3)(fc1)\n",
        "\t#add a dropout of 0.3 i.e kill 30% of the neurons at random to introduce generecity and avoid overfitting\n",
        "\n",
        "\tfc2=Dense(500,activation='relu')(drop1)\n",
        "\tdrop2=Dropout(0.3)(fc2)\n",
        "\t# add the fully connected layer with 500 neurons and apply a dropout of 0.3 same as the previous layer\n",
        "\tfc3=Dense(250,activation='relu')(drop2)\n",
        "\tdrop3=Dropout(0.3)(fc3)\n",
        "\tfc4=Dense(100,activation='relu')(drop3)\n",
        "\tdrop4=Dropout(0.3)(fc4)\n",
        "\tfc5=Dense(50,activation='relu')(drop4)\n",
        "\tdrop5=Dropout(0.3)(fc5)\n",
        "\tfc6=Dense(20,activation='relu')(drop5)\n",
        "\tdrop6=Dropout(0.3)(fc6)\n",
        "\tpredictions = Dense(2,activation='softmax')(drop6)\n",
        "\t# finally drop the model to 2 class prediction since we have to classify between two classes \n",
        "\t#and apply softmax activation since it gives us the class probabilities between 0 and 1\n",
        "\n",
        "\t# till now layers have been stacked onto one another\n",
        "\n",
        "\n",
        "\tmodel = Model(base_model.input, predictions)\n",
        "\t# specifies a model whose input layer is the input layer of the resnet model and output layer is \n",
        "\t# the predictions layer which gives the class probabilities of the two classes\n",
        "\n",
        "\tfor layer in base_model.layers:\n",
        "\t\tlayer.trainable=False\n",
        "\t# since resnet is already trained on the imagenet dataset it has already learned the basic features\n",
        "\t# such as lines , curves etc and thus we freeze the resnet model to avoid computation and save time\n",
        "\t# Hence these two lines set all the layers in the resnet model to not be trainable so that only the \n",
        "\t# fully connected layers that we have added are trainable\n",
        "\n",
        "\tadam=Adam(lr=0.001)\n",
        "\t# define a customised adam optimizer with a learning rate of 0.001. \n",
        "\t# You can also set other parameters such as momentum and decay\n",
        "\n",
        "\tmodel.compile(optimizer=adam, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\t# compile the model means to create a computation graph so that it knows that it has to use the\n",
        "\t# adam optimizer and compute the categorical cross-entropy loss during back propogation\n",
        "\t# also we define which all metrics we have to take track of. Loss is by default and we have\n",
        "\t# accuracy as well. But till now the model is just a graph and no data has been fed into it.\n",
        "\n",
        "\tmodel.summary()\n",
        "\t# prints the summary of the whole model we have just created\n",
        "\n",
        "\treturn model\n",
        "\t# return the made and compiled model\n",
        "datagen = ImageDataGenerator(\n",
        "\n",
        "        rotation_range=40,\n",
        "\n",
        "        width_shift_range=0.2,\n",
        "\n",
        "        height_shift_range=0.2,\n",
        "\n",
        "        shear_range=0.2,\n",
        "\n",
        "        zoom_range=0.2,\n",
        "\n",
        "        horizontal_flip=True,\n",
        "\n",
        "        fill_mode='nearest')\n",
        "\n",
        "def get_input():\n",
        "\tX=[]\n",
        "\tlabel=[]\n",
        "\tpath1=\"no_myopia\"\n",
        "\tpath2=\"pathological_myopia\"\n",
        "\tpath3=\"high_myopia\"\n",
        "\tlist1=os.listdir(path1)\n",
        "\tlist2=os.listdir(path2)\n",
        "\tlist3=os.listdir(path3)\n",
        "\tfor elem in list1:\n",
        "\t\timg=image.load_img(path1+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(0)\n",
        "\tfor elem in list2:\n",
        "\t\timg=image.load_img(path2+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(1)\n",
        "\tfor elem in list3:\n",
        "\t\timg=image.load_img(path3+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(2)\n",
        "\tX=preprocess_input(np.array(X))\n",
        "\tlabel=np.array(label)\n",
        "\tdatagen = ImageDataGenerator(rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\tprint (\"input taken\")\n",
        "\treturn X,label\n",
        "\n",
        "def fit_model(model,X,label):\n",
        "# function to train our model on the data given by X and its groundtruth given by label\n",
        "\n",
        "\tX_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.2, random_state=2)\n",
        "\t# split the data as 20% testing and 80% training with a random state of 2. Random state means that\n",
        "\t# everytime the data is randomly shuffled and then split but using the same random state means that\n",
        "\t# the data is shuffled similarly every time but if you change it to any other number it will shuffle\n",
        "\t# differently\n",
        "\tdatagen.fit(X_train)\n",
        "\tmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=32, save_to_dir=r'C:\\Users\\User\\Desktop\\Tutorial_ResNet', save_prefix='ewe', save_format='jpeg'),\n",
        "\t\t\t\t\t\t\t\tsteps_per_epoch=len(X_train) / 32, epochs=5)\n",
        "\n",
        "\tmodel_json = model.to_json()\n",
        "\t# converts the model architecture into a json file\n",
        "\n",
        "\twith open(\"model.json\", \"w\") as json_file:\n",
        "\t\tjson_file.write(model_json)\n",
        "\t\tprint(\"json saved\")\n",
        "\t# writes the model architecture into the json file named as model.json\n",
        "\n",
        "   \t#checkpoint=ModelCheckpoint(\"Model.h5\",monitor='val_acc',mode='max',save_best_only=True,save_weights_only=True)\n",
        "   \t# creates a checkpoint such that after every epoch it automatically saves the model weights \n",
        "   \t# monitor defines what we have to keep track of which in this case is validation accuracy.For\n",
        "   \t# training accuracy you can write acc and for loss write loss or val_loss\n",
        "   \t# Model.h5 defines the path where we want to save the weights\n",
        "   \t# mode defines when we have to save the weights when the thing being monitored is maximum or minimum\n",
        "   \t# save_best_only set to True means that only the best model is saved and save_weights_only means that\n",
        "   \t# only the model weights are stored since we have already stored the json file\n",
        "\n",
        "   \t# *********** it is always recommended to save the json and weights independently instead of the whole model at once **********\n",
        "\n",
        "   \t#callbacks_list=[checkpoint]\n",
        "   \t# creates a list of the checkpoint\n",
        "\t\n",
        "\t\n",
        "\tdatagen.fit(X_train)\n",
        "\tmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=1, class_mode=\"categorical\",target_size=(64, 64),color_mode=\"rgb\",save_to_dir=r'C:\\Users\\User\\Desktop\\training data\\aug x', save_prefix='fudus', save_format='jpeg'), steps_per_epoch=len(X_train) / 32, epochs=4)\n",
        "\n",
        "\n",
        "\n",
        "\tmodel.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=15, batch_size=32)\n",
        "\t#callbacks=callbacks_list\n",
        "\t# fits the model i.e provides the data to the built model to train it\n",
        "\t# X_train and y_train are the training data and the corresponding groundtruth\n",
        "\t# X_test and y_test are the validation data on which the trained model will be tested after every epoch\n",
        "\t# 15 epochs means that 15 iterations of training will be done\n",
        "\t# batch_size=32 refers \n",
        "\tscores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\tprint (\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "X,label=get_input()\n",
        "X,label=shuffle(X,label,random_state=2)\n",
        "model=get_model()\n",
        "fit_model(model,X,label)"
      ],
      "metadata": {
        "id": "zelpwlV7-kmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16_fine_tuning"
      ],
      "metadata": {
        "id": "OTDOZvj6-Ysu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Reshape\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "#from keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "#from keras.applications.alexnet import AlexNet,preprocess_input\n",
        "from keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from keras.models import model_from_json,model_from_config,load_model\n",
        "from keras.optimizers import SGD,RMSprop,adam,Adam\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from keras import models\n",
        "from keras import layers as lay\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from numpy import *\n",
        "import os\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "# sets the image shape specification to be (num_images,num_rows,num_columns,num_channels) \n",
        "#as if the backend is Theano num_channels come as the second argument\n",
        "\n",
        "def get_model():\n",
        "# function to make the model and compile it\n",
        "\n",
        "\t#base_model = ResNet50()\n",
        "\tbase_model = VGG16(weights='imagenet', include_top=True)\n",
        "\t# imports the base VGG16 model and stores it in base_model along with the preloaded ImageNet weights \n",
        "\n",
        "\tbase_model.summary()\n",
        "\t#prints the summary of the resnet model\n",
        "\t\n",
        "\tfl1 = base_model.get_layer('predictions').output\n",
        "\t#get the output of the layer of resnet with the name flatten_1\n",
        "\tfc1=Dense(1000,activation='relu')(fl1)\n",
        "\t#add a fully connected layer with 1000 neurons to the fl1 layer and apply relu activation on it\n",
        "\n",
        "\tdrop1=Dropout(0.3)(fc1)\n",
        "\t#add a dropout of 0.3 i.e kill 30% of the neurons at random to introduce generecity and avoid overfitting\n",
        "\n",
        "\tfc2=Dense(400,activation='relu')(drop1)\n",
        "\tdrop2=Dropout(0.3)(fc2)\n",
        "\t# add the fully connected layer with 500 neurons and apply a dropout of 0.3 same as the previous layer\n",
        "\tfc3=Dense(150,activation='relu')(drop2)\n",
        "\tdrop3=Dropout(0.3)(fc3)\n",
        "\tfc4=Dense(40,activation='relu')(drop3)\n",
        "\tdrop4=Dropout(0.3)(fc4)\n",
        "\tfc5=Dense(50,activation='relu')(drop4)\n",
        "\tdrop5=Dropout(0.3)(fc5)\n",
        "\tfc6=Dense(20,activation='relu')(drop5)\n",
        "\tdrop6=Dropout(0.3)(fc6)\n",
        "\tpredictions = Dense(3,activation='softmax')(drop4)\n",
        "\t# finally drop the model to 2 class prediction since we have to classify between two classes \n",
        "\t#and apply softmax activation since it gives us the class probabilities between 0 and 1\n",
        "\n",
        "\t# till now layers have been stacked onto one another\n",
        "\n",
        "\n",
        "\tmodel = Model(base_model.input, predictions)\n",
        "\t# specifies a model whose input layer is the input layer of the resnet model and output layer is \n",
        "\t# the predictions layer which gives the class probabilities of the two classes\n",
        "\n",
        "\tfor layer in base_model.layers:\n",
        "\t\tlayer.trainable=False\n",
        "\t# since resnet is already trained on the imagenet dataset it has already learned the basic features\n",
        "\t# such as lines , curves etc and thus we freeze the resnet model to avoid computation and save time\n",
        "\t# Hence these two lines set all the layers in the resnet model to not be trainable so that only the \n",
        "\t# fully connected layers that we have added are trainable\n",
        "\n",
        "\tadam=Adam(lr=0.001)\n",
        "\t# define a customised adam optimizer with a learning rate of 0.001. \n",
        "\t# You can also set other parameters such as momentum and decay\n",
        "\n",
        "\tmodel.compile(optimizer=adam, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\t# compile the model means to create a computation graph so that it knows that it has to use the\n",
        "\t# adam optimizer and compute the categorical cross-entropy loss during back propogation\n",
        "\t# also we define which all metrics we have to take track of. Loss is by default and we have\n",
        "\t# accuracy as well. But till now the model is just a graph and no data has been fed into it.\n",
        "\n",
        "\tmodel.summary()\n",
        "\t# prints the summary of the whole model we have just created\n",
        "\n",
        "\treturn model\n",
        "\t# return the made and compiled model\n",
        "\n",
        "def get_input():\n",
        "\tX=[]\n",
        "\tlabel=[]\n",
        "\tpath1=\"no_aug\"\n",
        "\tpath2=\"pathological_aug\"\n",
        "\tpath3=\"high_aug\"\n",
        "\tlist1=os.listdir(path1)\n",
        "\tlist2=os.listdir(path2)\n",
        "\tlist3=os.listdir(path3)\n",
        "\tfor elem in list1:\n",
        "\t\timg=image.load_img(path1+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(0)\n",
        "\tfor elem in list2:\n",
        "\t\timg=image.load_img(path2+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(1)\n",
        "\tfor elem in list3:\n",
        "\t\timg=image.load_img(path3+\"/\"+elem,target_size=(224,224))\n",
        "\t\tx=image.img_to_array(img)\n",
        "\t\tX.append(x)\n",
        "\t\tlabel.append(2)\n",
        "\tX=preprocess_input(np.array(X))\n",
        "\tlabel=np.array(label)\n",
        "\tprint (\"input taken\")\n",
        "\treturn X,label\n",
        "\n",
        "def fit_model(model,X,label):\n",
        "# function to train our model on the data given by X and its groundtruth given by label\n",
        "\n",
        "\tX_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.2, random_state=2)\n",
        "\t# split the data as 20% testing and 80% training with a random state of 2. Random state means that\n",
        "\t# everytime the data is randomly shuffled and then split but using the same random state means that\n",
        "\t# the data is shuffled similarly every time but if you change it to any other number it will shuffle\n",
        "\t# differently\n",
        "\n",
        "\tmodel_json = model.to_json()\n",
        "\t# converts the model architecture into a json file\n",
        "\n",
        "\twith open(\"model.json\", \"w\") as json_file:\n",
        "\t\tjson_file.write(model_json)\n",
        "\t\tprint(\"json saved\")\n",
        "\t# writes the model architecture into the json file named as model.json\n",
        "\n",
        "   \t#checkpoint=ModelCheckpoint(\"Model.h5\",monitor='val_acc',mode='max',save_best_only=True,save_weights_only=True)\n",
        "   \t# creates a checkpoint such that after every epoch it automatically saves the model weights \n",
        "   \t# monitor defines what we have to keep track of which in this case is validation accuracy.For\n",
        "   \t# training accuracy you can write acc and for loss write loss or val_loss\n",
        "   \t# Model.h5 defines the path where we want to save the weights\n",
        "   \t# mode defines when we have to save the weights when the thing being monitored is maximum or minimum\n",
        "   \t# save_best_only set to True means that only the best model is saved and save_weights_only means that\n",
        "   \t# only the model weights are stored since we have already stored the json file\n",
        "\n",
        "   \t# *********** it is always recommended to save the json and weights independently instead of the whole model at once **********\n",
        "\n",
        "   \t#callbacks_list=[checkpoint]\n",
        "   \t# creates a list of the checkpoint\n",
        "\t\n",
        "\n",
        "\t\n",
        "\t\n",
        "\n",
        "\tmodel.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=15, batch_size=32)\n",
        "\t#callbacks=callbacks_list\n",
        "\t# fits the model i.e provides the data to the built model to train it\n",
        "\t# X_train and y_train are the training data and the corresponding groundtruth\n",
        "\t# X_test and y_test are the validation data on which the trained model will be tested after every epoch\n",
        "\t# 15 epochs means that 15 iterations of training will be done\n",
        "\t# batch_size=32 refers \n",
        "\tscores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\tprint (\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "X,label=get_input()\n",
        "X,label=shuffle(X,label,random_state=2)\n",
        "model=get_model()\n",
        "fit_model(model,X,label)"
      ],
      "metadata": {
        "id": "O5z1yuK8-aqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BoTNet"
      ],
      "metadata": {
        "id": "DI4LuOqFGgIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bottleneck-transformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEoZR8BhGjXV",
        "outputId": "fce68104-cb74-41a7-f777-df3465eec2bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bottleneck-transformer-pytorch\n",
            "  Downloading bottleneck_transformer_pytorch-0.1.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from bottleneck-transformer-pytorch) (1.10.0+cu111)\n",
            "Collecting einops>=0.3\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->bottleneck-transformer-pytorch) (4.1.1)\n",
            "Installing collected packages: einops, bottleneck-transformer-pytorch\n",
            "Successfully installed bottleneck-transformer-pytorch-0.1.4 einops-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from bottleneck_transformer_pytorch import BottleStack\n",
        "\n",
        "layer = BottleStack(\n",
        "    dim = 256,              # 输入通道数\n",
        "    fmap_size = 56,         # 对于imagenet 224 x 224的图，特征图大小为56 x 56\n",
        "    dim_out = 2048,         # 输出通道数\n",
        "    proj_factor = 4,        # 压缩通道的倍数，压缩后的通道数 = 输入通道数 / proj_factor\n",
        "    downsample = True,      # 第一层是否下采样\n",
        "    heads = 4,              # MHSA 的头数\n",
        "    dim_head = 128,         # 每个头的维度，默认128维\n",
        "    rel_pos_emb = False,    # 是否使用相对的位置嵌入\n",
        "    activation = nn.ReLU()  # 激活函数\n",
        ")\n",
        "\n",
        "resnet = models.resnet50()  # 定义ResNet模型\n",
        "\n",
        "backbone = list(resnet.children())\n",
        "\n",
        "# 修改ResNet模型的最后几层\n",
        "model = nn.Sequential(\n",
        "    *backbone[:5],\n",
        "    layer,\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    nn.Flatten(1),\n",
        "    nn.Linear(2048, 1000)\n",
        ")\n",
        "\n",
        "# 使用 “BotNet”\n",
        "img = torch.randn(2, 3, 224, 224)\n",
        "preds = model(img)  # (2, 1000)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1RN-RHMGmQM",
        "outputId": "cff40ce5-c77a-4ca7-95e4-2154fc5a9c77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2341, 0.1400, 0.2848,  ..., 0.0853, 0.0395, 0.2891],\n",
            "        [0.2405, 0.1606, 0.2902,  ..., 0.0560, 0.0472, 0.2971]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our model"
      ],
      "metadata": {
        "id": "oVDSqhm9UZU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import 导入模块，每次使用模块中的函数都要是定是哪个模块\n",
        "# from … import * 导入模块，每次使用模块中的函数直接用就可以了，因为已经知道该函数是哪个模块中的了。\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "import torchvision as tv\n",
        "from torchvision import models,transforms,datasets\n",
        "\n",
        "# 查看Python解释器\n",
        "import sys\n",
        "print(sys.executable)\n",
        "\n",
        "# 测试GPU是否可用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "# 把Tensor转成Image，方便可视化\n",
        "from torchvision.transforms import ToPILImage\n",
        "show = ToPILImage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMI6jSvOmB-G",
        "outputId": "639408d5-8d16-45ad-d26b-ebdd13649284"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n",
            "Using gpu: True \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# 读取数据\n",
        "for dirname, _, filenames in os.walk('dataset/PALM-Training400/PALM-Training400/'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "DSsN43fph27i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}