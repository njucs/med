{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njucs/med/blob/master/PM/PALM_PaddleX_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTlR2fqwJoFL"
      },
      "source": [
        "**本方案使用TNT模型进行训练与预测，在有限训练次数下，取得了较稳定的成绩：0.99515**\n",
        "\n",
        "**采取的训练图像预处理方案：**\n",
        "\n",
        "- 随机垂直翻转\n",
        "- 随机角度翻转--0~20度\n",
        "- 缩放大小--（520，520）\n",
        "- 归一化--mean:[0.2, 0.3, 0.5], std:[0., 0., 0.]\n",
        "\n",
        "**采取的验证与预测图像预处理方案：**\n",
        "\n",
        "- 缩放大小--（520，520）\n",
        "- 归一化--mean:[0.2, 0.3, 0.5], std:[0., 0., 0.]\n",
        "- 数据集划分比例：0.8\n",
        "\n",
        "**TNT模型比较：**\n",
        "\n",
        "- 微调参数： tnt_s_patch16_224 得分 > tnt_b_patch16_224 得分\n",
        "\n",
        "**后期优化方向：**\n",
        "\n",
        "- 更合适的处理方式\n",
        "- patch大小与数量\n",
        "- 图片输入大小等"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_UpfeIEdr3g"
      },
      "source": [
        "## PaddleX配置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXF3enlRdtmw"
      },
      "source": [
        "### paddlex安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Obdbrdr1lePI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1dff52a-3d13-4b62-de25-68222acda97c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
            "Collecting paddlepaddle-gpu==2.2.2\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/88/06/edee9889fa8aff3eda68ca34528e13b694d6110e7ad678268eb2fa05994f/paddlepaddle_gpu-2.2.2-cp37-cp37m-manylinux1_x86_64.whl (435.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 435.4 MB 28 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==2.2.2) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==2.2.2) (1.15.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==2.2.2) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==2.2.2) (3.17.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==2.2.2) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==2.2.2) (1.21.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==2.2.2) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.2.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.2.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.2.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.2.2) (3.0.4)\n",
            "Installing collected packages: paddlepaddle-gpu\n",
            "Successfully installed paddlepaddle-gpu-2.2.2\n"
          ]
        }
      ],
      "source": [
        "# install PaddlePaddle-GPU\n",
        "!python -m pip install paddlepaddle-gpu==2.2.2 -i https://mirror.baidu.com/pypi/simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "327IadTzQ6N9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3308375b-db29-4b27-a7ce-dad0d574f510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
            "Collecting paddlex==1.3.11\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/d6/a2/07435f4aa1e51fe22bdf06c95d03bf1b78b7bc6625adbb51e35dc0804cc7/paddlex-1.3.11-py3-none-any.whl (516 kB)\n",
            "\u001b[K     |████████████████████████████████| 516 kB 242 kB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from paddlex==1.3.11) (2.0.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from paddlex==1.3.11) (5.4.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from paddlex==1.3.11) (4.64.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from paddlex==1.3.11) (3.13)\n",
            "Requirement already satisfied: shapely>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from paddlex==1.3.11) (1.8.1.post1)\n",
            "Requirement already satisfied: xlwt in /usr/local/lib/python3.7/dist-packages (from paddlex==1.3.11) (1.3.0)\n",
            "Collecting flask-cors\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from paddlex==1.3.11) (4.1.2.30)\n",
            "Collecting paddlehub==2.1.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/7a/29/3bd0ca43c787181e9c22fe44b944b64d7fcb14ce66d3bf4602d9ad2ac76c/paddlehub-2.1.0-py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting paddleslim==1.1.1\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/d1/77/e257227bed9a70ff0d35a4a3c4e70ac2d2362c803834c4c52018f7c4b762/paddleslim-1.1.1-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting visualdl>=2.0.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/87/c8/10d0d24822637d8e5493a73ad118640530195e45b1c71ae0e60606ff5f0e/visualdl-2.2.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from paddlex==1.3.11) (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from paddlehub==2.1.0->paddlex==1.3.11) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from paddlehub==2.1.0->paddlex==1.3.11) (21.3)\n",
            "Collecting colorlog\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/7d/54/e24efe5469ecb2710112055de87a2900e9494810bcfc25c12c7a0723eb64/colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting paddlenlp>=2.0.0rc5\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/12/9f/945342e60fe8400def08353440632eb3e4a1c7ed6deca4c6d2b864174655/paddlenlp-2.2.6-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 17.8 MB/s \n",
            "\u001b[?25hCollecting gunicorn>=19.10.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/e4/dd/5b190393e6066286773a67dfcc2f9492058e9b57c4867a95f1ba5caf0a83/gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting gitpython\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/83/32/ce68915670da6fd6b1e3fb4b3554b4462512f6441dddd194fc0f4f6ec653/GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 29.2 MB/s \n",
            "\u001b[?25hCollecting paddle2onnx>=0.5.1\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/cf/40/7ebb5e820e80b94dbd132164f61082df67f9588118580b93670543d6f7ad/paddle2onnx-0.9.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlehub==2.1.0->paddlex==1.3.11) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from paddlehub==2.1.0->paddlex==1.3.11) (3.2.2)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from paddlehub==2.1.0->paddlex==1.3.11) (22.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from paddlehub==2.1.0->paddlex==1.3.11) (3.6.0)\n",
            "Collecting rarfile\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/95/f4/c92fab227c7457e3b76a4096ccb655ded9deac869849cb03afbe55dfdc1e/rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from paddlehub==2.1.0->paddlex==1.3.11) (1.9)\n",
            "Requirement already satisfied: flask>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlehub==2.1.0->paddlex==1.3.11) (1.1.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex==1.3.11) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex==1.3.11) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex==1.3.11) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.0->paddlehub==2.1.0->paddlex==1.3.11) (7.1.2)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn>=19.10.0->paddlehub==2.1.0->paddlex==1.3.11) (57.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.0->paddlehub==2.1.0->paddlex==1.3.11) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddle2onnx>=0.5.1->paddlehub==2.1.0->paddlex==1.3.11) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from paddle2onnx>=0.5.1->paddlehub==2.1.0->paddlex==1.3.11) (3.17.3)\n",
            "Collecting onnx<=1.9.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/3f/9b/54c950d3256e27f970a83cd0504efb183a24312702deed0179453316dbd0/onnx-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx<=1.9.0->paddle2onnx>=0.5.1->paddlehub==2.1.0->paddlex==1.3.11) (4.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (3.1.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (0.70.12.2)\n",
            "Collecting datasets\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/3e/cf/19ab60e71740d369d5804d352f6c8a3d8f107a2d1664bd538cb3c475c2ce/datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 23.2 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 26.0 MB/s \n",
            "\u001b[?25hCollecting paddlefsl\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/fb/4a/25d1959a8f1fe5ee400f32fc9fc8b56d4fd6fc25315e23c0171f6e705e2a/paddlefsl-1.1.0-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (0.42.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddlex==1.3.11) (2.23.0)\n",
            "Collecting flake8>=3.7.9\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/34/39/cde2c8a227abb4f9ce62fe55586b920f438f1d2903a1a22514d0b982c333/flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting pre-commit\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/33/80/e95ffa9ec9649979d177229eaea8169ac9d3b32508fcb274630214d2287a/pre_commit-2.18.1-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddlex==1.3.11) (1.3.5)\n",
            "Collecting bce-python-sdk\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/55/ef/2a7e6c7692a036bae2570a9bcdcd7963ea54e07db97b4554c24d3cfacb21/bce-python-sdk-0.8.64.tar.gz (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 36.9 MB/s \n",
            "\u001b[?25hCollecting Flask-Babel>=1.0.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/ab/3e/02331179ffab8b79e0383606a028b6a60fb1b4419b84935edd43223406a0/Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting shellcheck-py\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/c1/be/448268ed5fb55bd5ff5076bc76c0a82023e3c3410d7a83c2f318dfc88a48/shellcheck_py-0.8.0.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 27.5 MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting importlib-metadata<4.3\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/22/51/52442c59db26637681148c21f8984eed58c9db67053a0a4783a047010c98/importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/43/fb/38848eb494af7df9aeb2d7673ace8b213313eb7e391691a79dbaeb6a838f/pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/15/94/bc43a2efb7b8615e38acde2b6624cae8c9ec86faf718ff5676c5179a7714/pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 789 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex==1.3.11) (2.9.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex==1.3.11) (2022.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddlex==1.3.11) (3.8.0)\n",
            "Collecting pycryptodome>=3.8.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/71/6b/965be3bec8fc1f6013739fea2bba86cf43a3be09ab7e29bd2134829c7615/pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 25.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex==1.3.11) (0.16.0)\n",
            "Collecting xxhash\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/ef/ac/0eb796cf052c392f1ae586452c89ca66164f7d4f655b039ca3d06e2291af/xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 41.5 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/dd/fe/80c594d62a7ff07730fd2cfc3a058498087436d8c938243e0610d1928f0e/aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 31.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (6.0.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/de/87/93d615a8387118359ec688a5a322afac8d64cc2d45e414f6a7144e8315c9/huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/a4/45/dcaa113699791da09107c231858ae75f34516064fc4f0db295df3df23b9e/fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (0.3.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->paddlehub==2.1.0->paddlex==1.3.11) (3.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddlex==1.3.11) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddlex==1.3.11) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddlex==1.3.11) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddlex==1.3.11) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 26.8 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/db/3f/1c876ed190e8fcd1a2faef3085427e5465076e28813a2499502633f7eed3/multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/3b/87/fe94898f2d44a93a35d5aa74671ed28094d80753a1113d68b799fab6dc22/aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/d1/ae/e4437fe5b5ba0fbccdaf8ecde8e3b6e8903793ca638c4706d034c0969ce1/frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 23.7 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/e8/b6/8d17e169d577ca7678b11cd0d3ceebb0a6089a7f4a2de4b945fe4b1c86db/asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/80/7f/af3ecdf87e8e41da7b133f1d61f82745f8c862bdade3b56addee3ad23956/yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 15.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/a3/7c/5d747655049bfbf75b5fcec57c8115896cb78d6fafa84f6d3ef4c0f13a98/gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/6d/01/7caa71608bc29952ae09b0be63a539e50d2484bc37747797a66a60679856/smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlehub==2.1.0->paddlex==1.3.11) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlehub==2.1.0->paddlex==1.3.11) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlehub==2.1.0->paddlex==1.3.11) (1.4.2)\n",
            "Collecting pyyaml\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/eb/5f/6e6fe6904e1a9c67bc2ca5629a69e7a5a0b17f079da838bab98a1e548b25/PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 28.3 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/6d/82/0a0ebd35bae9981dea55c06f8e6aaf44a49171ad798795c72c6f64cba4c2/cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting toml\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/44/6f/7120676b6d73228c96e17f1f794d8ab046fc910d781c8d151120c3f1569e/toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/54/73/56c89b343befb9c63e8117294d265458f0ff726fa2abcdc6bb5ec5e66a1a/nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/0c/4a/672fcebfc65877936f5a6eb1ded5a57e958a64e709500f79c2211397f7ab/identify-2.4.12-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting virtualenv>=20.0.8\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/9e/34/e86fc6a8f84329b49321a532b3c1fef103c67765df957fbb3852eea39d00/virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 24.4 MB/s \n",
            "\u001b[?25hCollecting distlib<1,>=0.3.1\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/ac/a3/8ee4f54d5f12e16eeeda6b7df3dfdbda24e6cc572c86ff959a4ce110391b/distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 22.3 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading https://mirror.baidu.com/pypi/packages/ed/22/967181c94c3a4063fe64e15331b4cb366bdd7dfbf46fcb8ad89650026fec/platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex==1.3.11) (1.1.0)\n",
            "Building wheels for collected packages: bce-python-sdk, seqeval\n",
            "  Building wheel for bce-python-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bce-python-sdk: filename=bce_python_sdk-0.8.64-py3-none-any.whl size=202973 sha256=04d5480c994a757b91f8526eb38336c85efd128adbab3445e8a2297810b8c965\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/b1/94/e33f9deb70bf6f2005d0deb22af1f4e3a71be8c25a49fb3c2b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=bac6be64090781292cb1a661b2bb9d01889c03c1032b22f496c2383b73f2c0cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/b6/38/9bf8fa2cb256deef8d102ce0f0b3cb501b50f8cc011d933b66\n",
            "Successfully built bce-python-sdk seqeval\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, platformdirs, importlib-metadata, fsspec, distlib, aiohttp, xxhash, virtualenv, toml, smmap, responses, pyflakes, pycryptodome, pycodestyle, nodeenv, mccabe, identify, huggingface-hub, cfgv, shellcheck-py, seqeval, sentencepiece, pre-commit, paddlefsl, onnx, gitdb, Flask-Babel, flake8, datasets, colorlog, colorama, bce-python-sdk, visualdl, rarfile, paddlenlp, paddle2onnx, gunicorn, gitpython, paddleslim, paddlehub, flask-cors, paddlex\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Flask-Babel-2.0.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 bce-python-sdk-0.8.64 cfgv-3.3.1 colorama-0.4.4 colorlog-6.6.0 datasets-2.1.0 distlib-0.3.4 flake8-4.0.1 flask-cors-3.0.10 frozenlist-1.3.0 fsspec-2022.3.0 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 huggingface-hub-0.5.1 identify-2.4.12 importlib-metadata-4.2.0 mccabe-0.6.1 multidict-6.0.2 nodeenv-1.6.0 onnx-1.9.0 paddle2onnx-0.9.5 paddlefsl-1.1.0 paddlehub-2.1.0 paddlenlp-2.2.6 paddleslim-1.1.1 paddlex-1.3.11 platformdirs-2.5.2 pre-commit-2.18.1 pycodestyle-2.8.0 pycryptodome-3.14.1 pyflakes-2.4.0 pyyaml-6.0 rarfile-4.0 responses-0.18.0 sentencepiece-0.1.96 seqeval-1.2.2 shellcheck-py-0.8.0.4 smmap-5.0.0 toml-0.10.2 urllib3-1.25.11 virtualenv-20.14.1 visualdl-2.2.3 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install paddlex==1.3.11 -i https://mirror.baidu.com/pypi/simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G2raUegcHg0K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import paddle\n",
        "from paddle import nn\n",
        "from paddle import optimizer\n",
        "from paddle import regularizer\n",
        "from paddle import metric\n",
        "from paddle.nn import loss\n",
        "from paddle.nn import Layer\n",
        "\n",
        "from paddle.io import Dataset, DataLoader\n",
        "from paddle.vision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcXcIYl4eInK"
      },
      "source": [
        "## 准备数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFjwp8QieKg5"
      },
      "source": [
        "### 准备数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uNgUT5Pw5VV",
        "outputId": "bc045292-1430-4265-b89b-d49fde3572cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Ophthalmology/PathologicMyopia\n"
          ]
        }
      ],
      "source": [
        "# 授权 Colab 访问 Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/MyDrive/'Colab Notebooks'/Ophthalmology/PathologicMyopia/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "skjCHL0gyD4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43e0992-0cf3-43ce-c0eb-fbb281c56ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "800\n",
            "400\n"
          ]
        }
      ],
      "source": [
        "!ls dataset/Train | wc -w\n",
        "!ls dataset/Train/fundus_image/ | wc -w\n",
        "!ls dataset/PALM-Testing400-Images/ | wc -w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o488t5FqHml8",
        "outputId": "4f41273e-ff05-4414-83f3-fe680287f21e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     imgName  Label\n",
              "0  V0001.jpg      0\n",
              "1  V0002.jpg      1\n",
              "2  V0003.jpg      1\n",
              "3  V0004.jpg      0\n",
              "4  V0005.jpg      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d18e809-b216-4151-a69b-045a433d0747\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imgName</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>V0001.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>V0002.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>V0003.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V0004.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>V0005.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d18e809-b216-4151-a69b-045a433d0747')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d18e809-b216-4151-a69b-045a433d0747 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d18e809-b216-4151-a69b-045a433d0747');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "Image_path = 'dataset/Train/fundus_image'\n",
        "Train_data = pd.read_excel('dataset/Train/Classification.xlsx')\n",
        "Train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f-WvQ2VMHpbc",
        "outputId": "a0b961f2-631d-412b-c68d-4a2b672c6fed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                imgName  Label\n",
              "0  dataset/Train/fundus_image/V0136.jpg      1\n",
              "1  dataset/Train/fundus_image/P0132.jpg      1\n",
              "2  dataset/Train/fundus_image/P0018.jpg      1\n",
              "3  dataset/Train/fundus_image/P0164.jpg      1\n",
              "4  dataset/Train/fundus_image/V0310.jpg      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c594e080-f754-4ca6-b9f9-5d3cf5a4b067\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imgName</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dataset/Train/fundus_image/V0136.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dataset/Train/fundus_image/P0132.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dataset/Train/fundus_image/P0018.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dataset/Train/fundus_image/P0164.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dataset/Train/fundus_image/V0310.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c594e080-f754-4ca6-b9f9-5d3cf5a4b067')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c594e080-f754-4ca6-b9f9-5d3cf5a4b067 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c594e080-f754-4ca6-b9f9-5d3cf5a4b067');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "for i in range(len(Train_data)):\n",
        "    Train_data.iloc[i, 0] = os.path.join(Image_path, Train_data.iloc[i, 0])\n",
        "Train_data = Train_data.sample(frac=1.0).reset_index(drop=True)\n",
        "Train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9byzefIAHp7e",
        "outputId": "911674bd-71ec-4851-936f-dc7af116cdca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          0  1\n",
              "0  dataset/PALM-Testing400-Images/T0001.jpg  0\n",
              "1  dataset/PALM-Testing400-Images/T0002.jpg  0\n",
              "2  dataset/PALM-Testing400-Images/T0003.jpg  0\n",
              "3  dataset/PALM-Testing400-Images/T0004.jpg  0\n",
              "4  dataset/PALM-Testing400-Images/T0005.jpg  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c860494-5aaf-4447-9abe-8ec76ae523e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dataset/PALM-Testing400-Images/T0001.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dataset/PALM-Testing400-Images/T0002.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dataset/PALM-Testing400-Images/T0003.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dataset/PALM-Testing400-Images/T0004.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dataset/PALM-Testing400-Images/T0005.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c860494-5aaf-4447-9abe-8ec76ae523e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c860494-5aaf-4447-9abe-8ec76ae523e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c860494-5aaf-4447-9abe-8ec76ae523e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Test_data = []\n",
        "Test_path = 'dataset/PALM-Testing400-Images'\n",
        "for _, _, files in os.walk(Test_path):\n",
        "    for i in files:\n",
        "        Test_data.append([i, 0])\n",
        "Test_data = np.asarray(Test_data)\n",
        "Test_data = pd.DataFrame(Test_data)\n",
        "Test_data = Test_data.sort_values(by=0, ascending=True).reset_index(drop=True)\n",
        "for i in range(len(Test_data)):\n",
        "    Test_data.iloc[i, 0] = os.path.join(Test_path, Test_data.iloc[i, 0])\n",
        "Test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B7HlY3rgHvuj"
      },
      "outputs": [],
      "source": [
        "class Train_Dataset(Dataset):\n",
        "    '''加载训练集\n",
        "        把数据加载函数拼进来\n",
        "    '''\n",
        "    def __init__(self, df, trans=None):\n",
        "        super(Train_Dataset, self).__init__()\n",
        "\n",
        "        self.df = df\n",
        "        \n",
        "        if trans is None:\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.RandomVerticalFlip(),\n",
        "                transforms.RandomRotation(20),\n",
        "                transforms.Resize(size=(520, 520)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.2, 0.3, 0.5])\n",
        "            ])\n",
        "        else:\n",
        "            self.trans = trans\n",
        "\n",
        "        self.lens = len(df)\n",
        "\n",
        "    def __getitem__(self, indexs):\n",
        "        im_data, im_label = self._load_img_and_label(self.df, indexs)\n",
        "        im_data = self.trans(im_data)\n",
        "        return im_data, paddle.to_tensor(im_label)\n",
        "\n",
        "    def _load_img_and_label(self, df, index):\n",
        "        '''加载DF中的路径为图片和标签\n",
        "            df: 输入DF\n",
        "            index: 第几条数据\n",
        "            mode: 加载训练集数据模式还是测试集模式--区别在于是否转换数据域\n",
        "        '''\n",
        "        assert index < self.lens, \\\n",
        "            'please check the index, which has more than the dataset length!'\n",
        "\n",
        "        im_data = cv.imread(df.iloc[index, 0], cv.COLOR_BGR2RGB)  # 转为RGB数据\n",
        "        im_label = int(df.iloc[index, 1])  # 标签\n",
        "        return np.asarray(im_data).astype('float32'), im_label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.lens\n",
        "\n",
        "class Test_Dataset(Dataset):\n",
        "    '''加载测试集\n",
        "        把数据加载函数拼进来\n",
        "    '''\n",
        "    def __init__(self, df, trans=None):\n",
        "        super(Test_Dataset, self).__init__()\n",
        "\n",
        "        self.df = df\n",
        "        \n",
        "        if trans is None:\n",
        "            self.trans = transforms.Compose([\n",
        "                transforms.Resize(size=(520, 520)),  # 保证迁移前后输入特征大小一致\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.2, 0.3, 0.5])\n",
        "            ])\n",
        "        else:\n",
        "            self.trans = trans\n",
        "\n",
        "        self.lens = len(df)\n",
        "\n",
        "    def __getitem__(self, indexs):\n",
        "        im_data, im_label = self._load_img_and_label(self.df, indexs)\n",
        "        im_data = self.trans(im_data)\n",
        "        return im_data, paddle.to_tensor(im_label)\n",
        "\n",
        "    def _load_img_and_label(self, df, index):\n",
        "        '''加载DF中的路径为图片和标签\n",
        "            df: 输入DF\n",
        "            index: 第几条数据\n",
        "            mode: 加载训练集数据模式还是测试集模式--区别在于是否转换数据域\n",
        "        '''\n",
        "        assert index < self.lens, \\\n",
        "            'please check the index, which has more than the dataset length!'\n",
        "\n",
        "        im_data = cv.imread(df.iloc[index, 0], cv.COLOR_BGR2RGB)  # 转为RGB数据\n",
        "        im_label = int(df.iloc[index, 1])  # 标签\n",
        "        return np.asarray(im_data).astype('float32'), im_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scPbUAv_elRe"
      },
      "source": [
        "## 训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "33FldCMwIF3t"
      },
      "outputs": [],
      "source": [
        "# 训练参数-=dict\n",
        "Train_Paramdict = {\n",
        "    'data_length':len(Train_data),  # 数据长度\n",
        "    'train_frac':0.8,              # 训练集比例\n",
        "    'num_class':2,                  # 类别\n",
        "    'epoches':20,                   # 训练轮次\n",
        "    'batchsize':8,                 # 批量大小\n",
        "    'lr':0.0001,                      # 学习率\n",
        "    'l2':0.0005                    # L2正则化参数\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wrzhd0t6IIUu"
      },
      "outputs": [],
      "source": [
        "# 数据集划分\n",
        "Fit_data  = Train_data.iloc[:int(Train_Paramdict['data_length']*Train_Paramdict['train_frac'])]\n",
        "Eval_data = Train_data.iloc[int(Train_Paramdict['data_length']*Train_Paramdict['train_frac']):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T8cWKOtzIKip"
      },
      "outputs": [],
      "source": [
        "# 数据加载\n",
        "Fit_dataset = Train_Dataset(Fit_data)\n",
        "Eval_dataset = Test_Dataset(Eval_data)\n",
        "All_dataset = Train_Dataset(Train_data)\n",
        "\n",
        "Fit_dataloader = DataLoader(Fit_dataset, batch_size=Train_Paramdict['batchsize'], shuffle=True)\n",
        "Eval_dataloader = DataLoader(Eval_dataset, batch_size=Train_Paramdict['batchsize'])\n",
        "All_dataloader = DataLoader(All_dataset, batch_size=Train_Paramdict['batchsize'], shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8oucAFJgNrpF"
      },
      "outputs": [],
      "source": [
        "import paddle\n",
        "from paddle import nn\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def _cfg(url='', **kwargs):\n",
        "    return {\n",
        "        'url': url,\n",
        "        'num_classes': 2, 'input_size': (3, 600, 600), 'pool_size': None,\n",
        "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
        "        'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5),\n",
        "        'first_conv': 'pixel_embed.proj', 'classifier': 'head',\n",
        "        **kwargs\n",
        "    }\n",
        "\n",
        "\n",
        "default_cfgs = {\n",
        "    'tnt_s_patch16_224': _cfg(\n",
        "        url='',\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "    'tnt_b_patch16_224': _cfg(\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "class Identity(nn.Layer):\n",
        "    r\"\"\"A placeholder identity operator that is argument-insensitive.\n",
        "    Args:\n",
        "        args: any argument (unused)\n",
        "        kwargs: any keyword argument (unused)\n",
        "    Examples::\n",
        "        >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)\n",
        "        >>> input = torch.randn(128, 20)\n",
        "        >>> output = m(input)\n",
        "        >>> print(output.size())\n",
        "        torch.Size([128, 20])\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "\n",
        "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
        "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
        "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
        "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
        "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
        "    'survival rate' as the argument.\n",
        "    \"\"\"\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = keep_prob + paddle.rand(shape=shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor()  # binarize\n",
        "    output = x.divide(keep_prob) * random_tensor\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "class DropPath(nn.Layer):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)\n",
        "\n",
        "\n",
        "class Attention(nn.Layer):\n",
        "    '''\n",
        "        注意力部分\n",
        "    '''\n",
        "\n",
        "    def __init__(self, dim, hidden_dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = hidden_dim // num_heads\n",
        "        self.head_dim = head_dim\n",
        "        self.scale = head_dim ** -0.5\n",
        "\n",
        "        self.qk = nn.Linear(dim, hidden_dim * 2, bias_attr=qkv_bias)\n",
        "        self.v = nn.Linear(dim, dim, bias_attr=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)  # no inplace\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        B, N, C = x.shape\n",
        "        qk = self.qk(x).reshape((B, N, 2, self.num_heads, self.head_dim)).transpose((2, 0, 3, 1, 4))\n",
        "        q, k = qk[0], qk[1]\n",
        "        v = self.v(x).reshape((B, N, self.num_heads, -1)).transpose((0, 2, 1, 3))\n",
        "\n",
        "        attn = paddle.matmul(q, k.transpose((0, 1, 3, 2))) * self.scale\n",
        "        attn = paddle.nn.functional.softmax(attn, axis=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = paddle.matmul(attn, v).transpose((0, 2, 1, 3)).reshape((B, N, -1))\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Mlp(nn.Layer):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super(Mlp, self).__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Layer):\n",
        "    \"\"\" TNT Block\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, in_dim, num_pixel, num_heads=12, in_num_head=4, mlp_ratio=4.,\n",
        "            qkv_bias=False, drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
        "        super(Block, self).__init__()\n",
        "        # Inner transformer\n",
        "        self.norm_in = norm_layer(in_dim)\n",
        "        self.attn_in = Attention(\n",
        "            in_dim, in_dim, num_heads=in_num_head, qkv_bias=qkv_bias,\n",
        "            attn_drop=attn_drop, proj_drop=drop)\n",
        "        \n",
        "        self.norm_mlp_in = norm_layer(in_dim)\n",
        "        self.mlp_in = Mlp(in_features=in_dim, hidden_features=int(in_dim * 4),\n",
        "            out_features=in_dim, act_layer=act_layer, drop=drop)\n",
        "        \n",
        "        self.norm1_proj = norm_layer(in_dim)\n",
        "        self.proj = nn.Linear(in_dim * num_pixel, dim, bias_attr=True)\n",
        "        # Outer transformer\n",
        "        self.norm_out = norm_layer(dim)\n",
        "        self.attn_out = Attention(\n",
        "            dim, dim, num_heads=num_heads, qkv_bias=qkv_bias,\n",
        "            attn_drop=attn_drop, proj_drop=drop)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else Identity()\n",
        "        \n",
        "        self.norm_mlp = norm_layer(dim)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=int(dim * mlp_ratio),\n",
        "            out_features=dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward(self, pixel_embed, patch_embed):\n",
        "        # inner\n",
        "        pixel_embed = pixel_embed + self.drop_path(self.attn_in(self.norm_in(pixel_embed)))\n",
        "        pixel_embed = pixel_embed + self.drop_path(self.mlp_in(self.norm_mlp_in(pixel_embed)))\n",
        "        # outer\n",
        "        B, N, C = patch_embed.shape\n",
        "        patch_embed[:, 1:] = patch_embed[:, 1:] + self.proj(self.norm1_proj(pixel_embed).reshape((B, N - 1, -1)))\n",
        "        patch_embed = patch_embed + self.drop_path(self.attn_out(self.norm_out(patch_embed)))\n",
        "        patch_embed = patch_embed + self.drop_path(self.mlp(self.norm_mlp(patch_embed)))\n",
        "        return pixel_embed, patch_embed\n",
        "\n",
        "\n",
        "class PixelEmbed(nn.Layer):\n",
        "    \"\"\" Image to Pixel Embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, in_dim=48, stride=4):\n",
        "        super(PixelEmbed, self).__init__()\n",
        "        num_patches = (img_size // patch_size) ** 2\n",
        "        self.img_size = img_size\n",
        "        self.num_patches = num_patches\n",
        "        self.in_dim = in_dim\n",
        "        new_patch_size = math.ceil(patch_size / stride)\n",
        "        self.new_patch_size = new_patch_size\n",
        "\n",
        "        self.proj = nn.Conv2D(in_chans, self.in_dim, kernel_size=7, padding=3, stride=stride)\n",
        "\n",
        "    def forward(self, x, pixel_pos):\n",
        "        B, C, H, W = x.shape\n",
        "        assert H == self.img_size and W == self.img_size, \\\n",
        "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size}*{self.img_size}).\"\n",
        "        x = self.proj(x)\n",
        "        x = nn.functional.unfold(x=x, kernel_sizes=self.new_patch_size, strides=self.new_patch_size)\n",
        "\n",
        "        x = x.transpose((0, 2, 1)).reshape((B * self.num_patches, self.in_dim, self.new_patch_size, self.new_patch_size))\n",
        "        x = x + pixel_pos\n",
        "\n",
        "        x = x.reshape((B * self.num_patches, self.in_dim, -1)).transpose((0, 2, 1))\n",
        "        return x\n",
        "\n",
        "\n",
        "class TNT(nn.Layer):\n",
        "    \"\"\" Transformer in Transformer - https://arxiv.org/abs/2103.00112\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, in_dim=48, depth=12,\n",
        "                 num_heads=12, in_num_head=4, mlp_ratio=4., qkv_bias=False, drop_rate=0., attn_drop_rate=0.,\n",
        "                 drop_path_rate=0., norm_layer=nn.LayerNorm, first_stride=4):\n",
        "        super(TNT, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
        "\n",
        "        self.pixel_embed = PixelEmbed(\n",
        "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, in_dim=in_dim, stride=first_stride)\n",
        "        num_patches = self.pixel_embed.num_patches\n",
        "        self.num_patches = num_patches\n",
        "        new_patch_size = self.pixel_embed.new_patch_size\n",
        "        num_pixel = new_patch_size ** 2\n",
        "        \n",
        "        self.norm1_proj = norm_layer(num_pixel * in_dim)\n",
        "        self.proj = nn.Linear(num_pixel * in_dim, embed_dim)\n",
        "        self.norm2_proj = norm_layer(embed_dim)\n",
        "            \n",
        "        # 创建参数\n",
        "        self.cls_token = paddle.create_parameter((1, 1, embed_dim), 'float32', attr=nn.initializer.Assign(paddle.zeros((1, 1, embed_dim))))\n",
        "        self.patch_pos = paddle.create_parameter((1, num_patches + 1, embed_dim), 'float32', attr=nn.initializer.Assign(paddle.zeros((1, num_patches + 1, embed_dim))))\n",
        "        self.pixel_pos = paddle.create_parameter((1, in_dim, new_patch_size, new_patch_size), 'float32', attr=nn.initializer.Assign(paddle.zeros((1, in_dim, new_patch_size, new_patch_size))))\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "\n",
        "        dpr = [x for x in paddle.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
        "        blocks = []\n",
        "        for i in range(depth):\n",
        "            blocks.append(Block(\n",
        "                dim=embed_dim, in_dim=in_dim, num_pixel=num_pixel, num_heads=num_heads, in_num_head=in_num_head,\n",
        "                mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, drop=drop_rate, attn_drop=attn_drop_rate,\n",
        "                drop_path=dpr[i], norm_layer=norm_layer))\n",
        "        self.blocks = nn.LayerList(blocks)\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "        self.head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "        with paddle.no_grad():\n",
        "            self.cls_token = paddle.create_parameter(self.cls_token.shape, 'float32', attr=nn.initializer.Assign(paddle.normal(self.cls_token, std=.02)))\n",
        "            self.patch_pos = paddle.create_parameter(self.patch_pos.shape, 'float32', attr=nn.initializer.Assign(paddle.normal(self.patch_pos, std=.02)))\n",
        "            self.pixel_pos = paddle.create_parameter(self.pixel_pos.shape, 'float32', attr=nn.initializer.Assign(paddle.normal(self.pixel_pos, std=.02)))\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            with paddle.no_grad():\n",
        "                m.weight = paddle.create_parameter(m.weight.shape, 'float32', attr=nn.initializer.Assign(paddle.normal(m.weight, std=.02)))\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                m.bias = paddle.create_parameter(m.bias.shape, 'float32', attr=nn.initializer.Constant(value=0.))\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            m.bias = paddle.create_parameter(m.bias.shape, 'float32', attr=nn.initializer.Constant(value=0.))\n",
        "            m.weight = paddle.create_parameter(m.weight.shape, 'float32', attr=nn.initializer.Constant(value=1.))\n",
        "\n",
        "    def no_weight_decay(self):\n",
        "        return {'patch_pos', 'pixel_pos', 'cls_token'}\n",
        "\n",
        "    def get_classifier(self):\n",
        "        return self.head\n",
        "\n",
        "    def reset_classifier(self, num_classes, global_pool=''):\n",
        "        self.num_classes = num_classes\n",
        "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        B = x.shape[0]\n",
        "        pixel_embed = self.pixel_embed(x, self.pixel_pos)\n",
        "        \n",
        "        patch_embed = self.norm2_proj(self.proj(self.norm1_proj(pixel_embed.reshape((B, self.num_patches, -1)))))\n",
        "        patch_embed = paddle.concat((self.cls_token.expand([B, self.cls_token.shape[1],self.cls_token.shape[2]]), patch_embed), axis=1)  # expand\n",
        "        patch_embed = patch_embed + self.patch_pos\n",
        "        patch_embed = self.pos_drop(patch_embed)\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            pixel_embed, patch_embed = blk(pixel_embed, patch_embed)\n",
        "\n",
        "        patch_embed = self.norm(patch_embed)\n",
        "        return patch_embed[:, 0]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def tnt_s_patch16_224(pretrained=False, **kwargs):\n",
        "    model = TNT(patch_size=16, embed_dim=384, in_dim=24, depth=12, num_heads=6, in_num_head=4,\n",
        "        qkv_bias=False, **kwargs)\n",
        "    model.default_cfg = default_cfgs['tnt_s_patch16_224']\n",
        "    if pretrained:\n",
        "        load_pretrained(\n",
        "            model, num_classes=model.num_classes, in_chans=kwargs.get('in_chans', 3))\n",
        "    return model\n",
        "\n",
        "\n",
        "def tnt_b_patch16_224(pretrained=False, **kwargs):\n",
        "    model = TNT(patch_size=16, embed_dim=640, in_dim=40, depth=12, num_heads=10, in_num_head=4,\n",
        "        qkv_bias=False, **kwargs)\n",
        "    model.default_cfg = default_cfgs['tnt_b_patch16_224']\n",
        "    if pretrained:\n",
        "        load_pretrained(\n",
        "            model, num_classes=model.num_classes, in_chans=kwargs.get('in_chans', 3))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kggqrRytemhy"
      },
      "outputs": [],
      "source": [
        "# 创建模型\n",
        "#import tnt_s_patch16_224, tnt_b_patch16_224\n",
        "model = tnt_s_patch16_224(img_size=520, num_classes=2)\n",
        "model = paddle.Model(model)\n",
        "\n",
        "lr = optimizer.lr.LinearWarmup(\n",
        "    learning_rate=Train_Paramdict['lr'],\n",
        "    warmup_steps = 2000,\n",
        "    start_lr = 0, \n",
        "    end_lr = Train_Paramdict['lr']\n",
        ")\n",
        "\n",
        "O = optimizer.Adam(lr, parameters=model.parameters(), weight_decay=regularizer.L2Decay(Train_Paramdict['l2']))\n",
        "L = loss.CrossEntropyLoss()\n",
        "M = metric.Accuracy()\n",
        "\n",
        "model.prepare(O, L, M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxf3l3cdIQ2O",
        "outputId": "114c03e8-a95a-49d8-e66a-032ed350c2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:130: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if data.dtype == np.object:\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return (isinstance(seq, collections.Sequence) and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 10/80 - loss: 2.0699 - acc: 0.5000 - 5s/step\n",
            "step 20/80 - loss: 1.0156 - acc: 0.5375 - 4s/step\n",
            "step 30/80 - loss: 0.6353 - acc: 0.6000 - 4s/step\n",
            "step 40/80 - loss: 0.3460 - acc: 0.6125 - 4s/step\n",
            "step 50/80 - loss: 0.4992 - acc: 0.6350 - 3s/step\n",
            "step 60/80 - loss: 0.5391 - acc: 0.6667 - 3s/step\n",
            "step 70/80 - loss: 0.4074 - acc: 0.6893 - 3s/step\n",
            "step 80/80 - loss: 0.6729 - acc: 0.7078 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 0.8000 - acc: 0.8125 - 1s/step\n",
            "step 20/20 - loss: 0.6379 - acc: 0.7875 - 2s/step\n",
            "Eval samples: 160\n",
            "Epoch 2/20\n",
            "step 10/80 - loss: 0.5294 - acc: 0.7375 - 3s/step\n",
            "step 20/80 - loss: 0.3377 - acc: 0.7625 - 3s/step\n",
            "step 30/80 - loss: 0.1183 - acc: 0.7708 - 3s/step\n",
            "step 40/80 - loss: 0.4803 - acc: 0.7875 - 3s/step\n",
            "step 50/80 - loss: 0.3944 - acc: 0.7975 - 3s/step\n",
            "step 60/80 - loss: 0.4662 - acc: 0.7979 - 3s/step\n",
            "step 70/80 - loss: 0.3313 - acc: 0.8036 - 3s/step\n",
            "step 80/80 - loss: 0.2875 - acc: 0.8094 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.0763 - acc: 0.8250 - 1s/step\n",
            "step 20/20 - loss: 0.6767 - acc: 0.8125 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 3/20\n",
            "step 10/80 - loss: 0.5226 - acc: 0.8500 - 3s/step\n",
            "step 20/80 - loss: 0.3452 - acc: 0.8125 - 3s/step\n",
            "step 30/80 - loss: 0.3004 - acc: 0.8083 - 3s/step\n",
            "step 40/80 - loss: 0.4445 - acc: 0.8063 - 3s/step\n",
            "step 50/80 - loss: 0.2189 - acc: 0.8300 - 3s/step\n",
            "step 60/80 - loss: 0.1870 - acc: 0.8313 - 3s/step\n",
            "step 70/80 - loss: 0.1156 - acc: 0.8339 - 3s/step\n",
            "step 80/80 - loss: 0.5070 - acc: 0.8328 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.1659 - acc: 0.8375 - 1s/step\n",
            "step 20/20 - loss: 0.9529 - acc: 0.8063 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 4/20\n",
            "step 10/80 - loss: 0.4383 - acc: 0.8750 - 3s/step\n",
            "step 20/80 - loss: 0.1666 - acc: 0.8375 - 3s/step\n",
            "step 30/80 - loss: 0.3056 - acc: 0.8250 - 3s/step\n",
            "step 40/80 - loss: 0.1569 - acc: 0.8094 - 3s/step\n",
            "step 50/80 - loss: 1.0891 - acc: 0.8125 - 3s/step\n",
            "step 60/80 - loss: 0.0737 - acc: 0.8292 - 3s/step\n",
            "step 70/80 - loss: 0.1430 - acc: 0.8232 - 3s/step\n",
            "step 80/80 - loss: 0.4355 - acc: 0.8266 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.1869 - acc: 0.8500 - 1s/step\n",
            "step 20/20 - loss: 0.8302 - acc: 0.8187 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 5/20\n",
            "step 10/80 - loss: 0.2936 - acc: 0.9250 - 3s/step\n",
            "step 20/80 - loss: 0.6965 - acc: 0.8750 - 3s/step\n",
            "step 30/80 - loss: 0.0771 - acc: 0.8542 - 3s/step\n",
            "step 40/80 - loss: 0.3641 - acc: 0.8406 - 3s/step\n",
            "step 50/80 - loss: 0.1986 - acc: 0.8400 - 3s/step\n",
            "step 60/80 - loss: 0.1049 - acc: 0.8500 - 3s/step\n",
            "step 70/80 - loss: 0.1786 - acc: 0.8446 - 3s/step\n",
            "step 80/80 - loss: 0.1654 - acc: 0.8328 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.1085 - acc: 0.8500 - 1s/step\n",
            "step 20/20 - loss: 0.6122 - acc: 0.8500 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 6/20\n",
            "step 10/80 - loss: 0.2505 - acc: 0.8875 - 3s/step\n",
            "step 20/80 - loss: 0.2346 - acc: 0.8438 - 3s/step\n",
            "step 30/80 - loss: 0.3768 - acc: 0.8375 - 3s/step\n",
            "step 40/80 - loss: 0.6367 - acc: 0.8469 - 3s/step\n",
            "step 50/80 - loss: 0.1238 - acc: 0.8500 - 3s/step\n",
            "step 60/80 - loss: 0.1092 - acc: 0.8583 - 3s/step\n",
            "step 70/80 - loss: 0.1135 - acc: 0.8500 - 3s/step\n",
            "step 80/80 - loss: 0.2494 - acc: 0.8516 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.0547 - acc: 0.8750 - 1s/step\n",
            "step 20/20 - loss: 0.5834 - acc: 0.8688 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 7/20\n",
            "step 10/80 - loss: 0.5941 - acc: 0.9250 - 3s/step\n",
            "step 20/80 - loss: 0.0546 - acc: 0.9250 - 3s/step\n",
            "step 30/80 - loss: 0.3411 - acc: 0.9000 - 3s/step\n",
            "step 40/80 - loss: 0.5838 - acc: 0.8812 - 3s/step\n",
            "step 50/80 - loss: 0.8431 - acc: 0.8800 - 3s/step\n",
            "step 60/80 - loss: 0.1225 - acc: 0.8708 - 3s/step\n",
            "step 70/80 - loss: 0.2522 - acc: 0.8679 - 3s/step\n",
            "step 80/80 - loss: 1.1890 - acc: 0.8547 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.3633 - acc: 0.8500 - 1s/step\n",
            "step 20/20 - loss: 1.3514 - acc: 0.7875 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 8/20\n",
            "step 10/80 - loss: 0.1962 - acc: 0.8250 - 3s/step\n",
            "step 20/80 - loss: 0.1768 - acc: 0.8187 - 3s/step\n",
            "step 30/80 - loss: 0.3493 - acc: 0.8375 - 3s/step\n",
            "step 40/80 - loss: 0.2137 - acc: 0.8500 - 3s/step\n",
            "step 50/80 - loss: 0.1568 - acc: 0.8575 - 3s/step\n",
            "step 60/80 - loss: 0.1725 - acc: 0.8708 - 3s/step\n",
            "step 70/80 - loss: 0.0279 - acc: 0.8786 - 3s/step\n",
            "step 80/80 - loss: 0.1784 - acc: 0.8781 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.1326 - acc: 0.8125 - 1s/step\n",
            "step 20/20 - loss: 0.4217 - acc: 0.8562 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 9/20\n",
            "step 10/80 - loss: 0.3037 - acc: 0.8625 - 3s/step\n",
            "step 20/80 - loss: 0.3971 - acc: 0.8438 - 3s/step\n",
            "step 30/80 - loss: 0.1025 - acc: 0.8542 - 3s/step\n",
            "step 40/80 - loss: 0.0349 - acc: 0.8656 - 3s/step\n",
            "step 50/80 - loss: 0.8588 - acc: 0.8675 - 3s/step\n",
            "step 60/80 - loss: 0.1446 - acc: 0.8792 - 3s/step\n",
            "step 70/80 - loss: 0.0892 - acc: 0.8857 - 3s/step\n",
            "step 80/80 - loss: 0.0312 - acc: 0.8828 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 0.8141 - acc: 0.9000 - 1s/step\n",
            "step 20/20 - loss: 0.4428 - acc: 0.9062 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 10/20\n",
            "step 10/80 - loss: 0.1886 - acc: 0.8875 - 3s/step\n",
            "step 20/80 - loss: 0.0664 - acc: 0.9062 - 3s/step\n",
            "step 30/80 - loss: 0.0411 - acc: 0.9208 - 3s/step\n",
            "step 40/80 - loss: 0.9721 - acc: 0.9031 - 3s/step\n",
            "step 50/80 - loss: 0.5323 - acc: 0.8775 - 3s/step\n",
            "step 60/80 - loss: 0.1343 - acc: 0.8812 - 3s/step\n",
            "step 70/80 - loss: 0.2013 - acc: 0.8804 - 3s/step\n",
            "step 80/80 - loss: 0.3655 - acc: 0.8828 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 0.8505 - acc: 0.9250 - 1s/step\n",
            "step 20/20 - loss: 0.5101 - acc: 0.9125 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 11/20\n",
            "step 10/80 - loss: 0.0630 - acc: 0.9375 - 3s/step\n",
            "step 20/80 - loss: 0.0739 - acc: 0.9313 - 3s/step\n",
            "step 30/80 - loss: 1.8639 - acc: 0.9125 - 3s/step\n",
            "step 40/80 - loss: 0.0609 - acc: 0.8875 - 3s/step\n",
            "step 50/80 - loss: 0.0303 - acc: 0.8950 - 3s/step\n",
            "step 60/80 - loss: 0.4889 - acc: 0.8938 - 3s/step\n",
            "step 70/80 - loss: 0.2020 - acc: 0.8893 - 3s/step\n",
            "step 80/80 - loss: 0.4929 - acc: 0.8828 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 0.8441 - acc: 0.8500 - 1s/step\n",
            "step 20/20 - loss: 0.9615 - acc: 0.7875 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 12/20\n",
            "step 10/80 - loss: 0.1358 - acc: 0.9375 - 3s/step\n",
            "step 20/80 - loss: 0.2878 - acc: 0.9187 - 3s/step\n",
            "step 30/80 - loss: 0.3475 - acc: 0.9042 - 3s/step\n",
            "step 40/80 - loss: 0.3777 - acc: 0.8969 - 3s/step\n",
            "step 50/80 - loss: 0.0613 - acc: 0.9025 - 3s/step\n",
            "step 60/80 - loss: 0.5151 - acc: 0.9083 - 3s/step\n",
            "step 70/80 - loss: 0.2329 - acc: 0.9054 - 3s/step\n",
            "step 80/80 - loss: 0.4280 - acc: 0.9031 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 0.8703 - acc: 0.9375 - 1s/step\n",
            "step 20/20 - loss: 0.4889 - acc: 0.9313 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 13/20\n",
            "step 10/80 - loss: 0.0779 - acc: 0.9375 - 3s/step\n",
            "step 20/80 - loss: 0.2982 - acc: 0.8875 - 3s/step\n",
            "step 30/80 - loss: 0.1055 - acc: 0.9125 - 3s/step\n",
            "step 40/80 - loss: 0.2426 - acc: 0.9062 - 3s/step\n",
            "step 50/80 - loss: 0.1845 - acc: 0.9050 - 3s/step\n",
            "step 60/80 - loss: 0.4707 - acc: 0.9104 - 3s/step\n",
            "step 70/80 - loss: 0.1030 - acc: 0.9143 - 3s/step\n",
            "step 80/80 - loss: 0.3840 - acc: 0.9203 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.3318 - acc: 0.9125 - 1s/step\n",
            "step 20/20 - loss: 0.5407 - acc: 0.9250 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 14/20\n",
            "step 10/80 - loss: 0.0448 - acc: 0.9500 - 3s/step\n",
            "step 20/80 - loss: 0.6910 - acc: 0.9125 - 3s/step\n",
            "step 30/80 - loss: 0.1513 - acc: 0.8958 - 3s/step\n",
            "step 40/80 - loss: 0.1277 - acc: 0.8844 - 3s/step\n",
            "step 50/80 - loss: 0.1121 - acc: 0.8875 - 3s/step\n",
            "step 60/80 - loss: 0.2954 - acc: 0.8896 - 3s/step\n",
            "step 70/80 - loss: 0.0096 - acc: 0.9054 - 3s/step\n",
            "step 80/80 - loss: 0.0912 - acc: 0.9109 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.2594 - acc: 0.9125 - 1s/step\n",
            "step 20/20 - loss: 0.5353 - acc: 0.9187 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 15/20\n",
            "step 10/80 - loss: 0.2582 - acc: 0.9250 - 3s/step\n",
            "step 20/80 - loss: 0.1351 - acc: 0.9187 - 3s/step\n",
            "step 30/80 - loss: 0.2424 - acc: 0.9292 - 3s/step\n",
            "step 40/80 - loss: 0.2578 - acc: 0.9125 - 3s/step\n",
            "step 50/80 - loss: 0.9476 - acc: 0.8975 - 3s/step\n",
            "step 60/80 - loss: 0.0994 - acc: 0.8979 - 3s/step\n",
            "step 70/80 - loss: 0.2589 - acc: 0.8929 - 3s/step\n",
            "step 80/80 - loss: 0.0915 - acc: 0.8953 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.0599 - acc: 0.8750 - 1s/step\n",
            "step 20/20 - loss: 1.0359 - acc: 0.8438 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 16/20\n",
            "step 10/80 - loss: 0.0863 - acc: 0.9375 - 3s/step\n",
            "step 20/80 - loss: 0.0578 - acc: 0.9563 - 3s/step\n",
            "step 30/80 - loss: 0.0773 - acc: 0.9292 - 3s/step\n",
            "step 40/80 - loss: 0.1882 - acc: 0.9094 - 3s/step\n",
            "step 50/80 - loss: 0.1124 - acc: 0.9175 - 3s/step\n",
            "step 60/80 - loss: 0.2074 - acc: 0.9146 - 3s/step\n",
            "step 70/80 - loss: 0.2846 - acc: 0.9107 - 3s/step\n",
            "step 80/80 - loss: 0.0867 - acc: 0.9172 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.1209 - acc: 0.9250 - 1s/step\n",
            "step 20/20 - loss: 0.5143 - acc: 0.9250 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 17/20\n",
            "step 10/80 - loss: 0.4422 - acc: 0.9125 - 3s/step\n",
            "step 20/80 - loss: 0.0186 - acc: 0.9375 - 3s/step\n",
            "step 30/80 - loss: 0.0199 - acc: 0.9417 - 3s/step\n",
            "step 40/80 - loss: 0.2062 - acc: 0.9219 - 3s/step\n",
            "step 50/80 - loss: 0.5394 - acc: 0.9225 - 3s/step\n",
            "step 60/80 - loss: 0.0206 - acc: 0.9208 - 3s/step\n",
            "step 70/80 - loss: 0.4022 - acc: 0.9268 - 3s/step\n",
            "step 80/80 - loss: 0.0239 - acc: 0.9328 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.4119 - acc: 0.8500 - 1s/step\n",
            "step 20/20 - loss: 0.4247 - acc: 0.8875 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 18/20\n",
            "step 10/80 - loss: 0.0592 - acc: 0.9375 - 3s/step\n",
            "step 20/80 - loss: 0.1244 - acc: 0.9313 - 3s/step\n",
            "step 30/80 - loss: 0.3530 - acc: 0.9250 - 3s/step\n",
            "step 40/80 - loss: 0.4163 - acc: 0.9125 - 3s/step\n",
            "step 50/80 - loss: 0.2373 - acc: 0.9075 - 3s/step\n",
            "step 60/80 - loss: 0.0792 - acc: 0.9104 - 3s/step\n",
            "step 70/80 - loss: 0.0358 - acc: 0.9125 - 3s/step\n",
            "step 80/80 - loss: 0.0477 - acc: 0.9156 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.0664 - acc: 0.9375 - 1s/step\n",
            "step 20/20 - loss: 0.7128 - acc: 0.9250 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 19/20\n",
            "step 10/80 - loss: 0.5070 - acc: 0.9375 - 3s/step\n",
            "step 20/80 - loss: 0.6210 - acc: 0.9250 - 3s/step\n",
            "step 30/80 - loss: 0.1902 - acc: 0.9208 - 3s/step\n",
            "step 40/80 - loss: 0.0466 - acc: 0.9313 - 3s/step\n",
            "step 50/80 - loss: 0.1185 - acc: 0.9225 - 3s/step\n",
            "step 60/80 - loss: 0.6582 - acc: 0.9125 - 3s/step\n",
            "step 70/80 - loss: 0.0514 - acc: 0.9089 - 3s/step\n",
            "step 80/80 - loss: 0.0884 - acc: 0.9109 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 1.1709 - acc: 0.8500 - 1s/step\n",
            "step 20/20 - loss: 0.4132 - acc: 0.8875 - 1s/step\n",
            "Eval samples: 160\n",
            "Epoch 20/20\n",
            "step 10/80 - loss: 0.0118 - acc: 0.9375 - 3s/step\n",
            "step 20/80 - loss: 0.0697 - acc: 0.9313 - 3s/step\n",
            "step 30/80 - loss: 0.0735 - acc: 0.9375 - 3s/step\n",
            "step 40/80 - loss: 0.1642 - acc: 0.9437 - 3s/step\n",
            "step 50/80 - loss: 0.1460 - acc: 0.9375 - 3s/step\n",
            "step 60/80 - loss: 0.0217 - acc: 0.9396 - 3s/step\n",
            "step 70/80 - loss: 0.0174 - acc: 0.9429 - 3s/step\n",
            "step 80/80 - loss: 0.9030 - acc: 0.9359 - 3s/step\n",
            "Eval begin...\n",
            "step 10/20 - loss: 0.8536 - acc: 0.8750 - 1s/step\n",
            "step 20/20 - loss: 0.7668 - acc: 0.8500 - 1s/step\n",
            "Eval samples: 160\n"
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "    Fit_dataloader,\n",
        "    Eval_dataloader,\n",
        "    epochs=Train_Paramdict['epoches']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V19HnpEheuLT"
      },
      "source": [
        "## 预测"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8ue9m2Rve5AA"
      },
      "outputs": [],
      "source": [
        "# 数据加载\n",
        "Test_dataset = Test_Dataset(Test_data)\n",
        "Test_dataloader = DataLoader(Test_dataset, batch_size=Train_Paramdict['batchsize'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BzPEkjK6IXyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fef4110-d095-47bd-c70b-2c671a9bf62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict begin...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:130: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if data.dtype == np.object:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 50/50 [==============================] - 4s/step          \n",
            "Predict samples: 400\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(Test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IYvQv6qGIYOo"
      },
      "outputs": [],
      "source": [
        "results = np.asarray(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "agUbO4zBIaNM"
      },
      "outputs": [],
      "source": [
        "import paddle.nn.functional as F\n",
        "\n",
        "submit_result = []\n",
        "for i in results[0]:\n",
        "    i = paddle.to_tensor(i)\n",
        "    i = F.softmax(i)\n",
        "    result = i[:, 1]\n",
        "    submit_result += result.numpy().tolist()\n",
        "len(submit_result)\n",
        "\n",
        "submit_result = np.asarray(submit_result)\n",
        "\n",
        "Test_data.iloc[:, 1] = submit_result\n",
        "Test_data.head()\n",
        "\n",
        "Submit_data = Test_data.copy()\n",
        "Submit_data.head()\n",
        "\n",
        "Submit_data.columns = ['FileName', 'PM Risk']\n",
        "Submit_data.head()\n",
        "\n",
        "for i in range(len(Submit_data)):\n",
        "    Submit_data.iloc[i, 0] = Submit_data.iloc[i, 0][-9:]\n",
        "Submit_data.head()\n",
        "\n",
        "Submit_data.to_csv('PALM_PaddleX_10/Classification_Results.csv', index=False, float_format=\"%.1f\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PALM_PaddleX_10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2rxtvbcOWw7A719CCwS5l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}